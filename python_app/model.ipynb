{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "df = pd.read_csv(\"loan_approval_dataset_normalized.csv\")\n",
    "# delete the last row\n",
    "df = df.drop(df.index[-1])\n",
    "# suffle the data\n",
    "df = df.sample(frac=1, random_state=12).reset_index(drop=True)\n",
    "\n",
    "X = df.drop([\" loan_status\"], axis=1)\n",
    "Y = df[\" loan_status\"]\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=1 - train_ratio,\n",
    "    random_state=12,\n",
    ")\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    test_size=test_ratio / (test_ratio + validation_ratio),\n",
    "    random_state=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3201\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = x_train.shape\n",
    "\n",
    "# Print the size\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H=64, D_out=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(D_in, H)\n",
    "        self.fc2 = nn.Linear(H, D_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Training Loss: 0.6935189693581825\n",
      "Epoch 1/1000, Validation Loss: 0.6567733705043792\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 2/1000, Training Loss: 0.6452055970827738\n",
      "Epoch 2/1000, Validation Loss: 0.6414810538291931\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 3/1000, Training Loss: 0.6351089325605654\n",
      "Epoch 3/1000, Validation Loss: 0.6189949035644531\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 4/1000, Training Loss: 0.599006776716195\n",
      "Epoch 4/1000, Validation Loss: 0.5922068655490875\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 5/1000, Training Loss: 0.571981781837987\n",
      "Epoch 5/1000, Validation Loss: 0.5518928110599518\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 6/1000, Training Loss: 0.540844562591291\n",
      "Epoch 6/1000, Validation Loss: 0.5180741071701049\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 7/1000, Training Loss: 0.5076703090293735\n",
      "Epoch 7/1000, Validation Loss: 0.48732136487960814\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 8/1000, Training Loss: 0.48738059050896587\n",
      "Epoch 8/1000, Validation Loss: 0.46233848929405214\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 9/1000, Training Loss: 0.45069946114923437\n",
      "Epoch 9/1000, Validation Loss: 0.43656887114048004\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 10/1000, Training Loss: 0.43803716290230843\n",
      "Epoch 10/1000, Validation Loss: 0.41362920999526975\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 11/1000, Training Loss: 0.41274601571700154\n",
      "Epoch 11/1000, Validation Loss: 0.39314200580120084\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 12/1000, Training Loss: 0.3917568366901547\n",
      "Epoch 12/1000, Validation Loss: 0.37467063367366793\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 13/1000, Training Loss: 0.3691614141651228\n",
      "Epoch 13/1000, Validation Loss: 0.3582853227853775\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 14/1000, Training Loss: 0.35702183375171587\n",
      "Epoch 14/1000, Validation Loss: 0.34088920056819916\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 15/1000, Training Loss: 0.35808039588086743\n",
      "Epoch 15/1000, Validation Loss: 0.32688526809215546\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 16/1000, Training Loss: 0.32730507500031414\n",
      "Epoch 16/1000, Validation Loss: 0.3153095841407776\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 17/1000, Training Loss: 0.3092824138847052\n",
      "Epoch 17/1000, Validation Loss: 0.30391819179058077\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 18/1000, Training Loss: 0.2985506481399723\n",
      "Epoch 18/1000, Validation Loss: 0.29294185638427733\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 19/1000, Training Loss: 0.29057902302227767\n",
      "Epoch 19/1000, Validation Loss: 0.28571491986513137\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 20/1000, Training Loss: 0.2880705282384274\n",
      "Epoch 20/1000, Validation Loss: 0.2780257433652878\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 21/1000, Training Loss: 0.27712025478774427\n",
      "Epoch 21/1000, Validation Loss: 0.27046382129192353\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 22/1000, Training Loss: 0.31331809449429604\n",
      "Epoch 22/1000, Validation Loss: 0.26336050778627396\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 23/1000, Training Loss: 0.27884556820579603\n",
      "Epoch 23/1000, Validation Loss: 0.2607077658176422\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 24/1000, Training Loss: 0.2613717357938488\n",
      "Epoch 24/1000, Validation Loss: 0.2578286036849022\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 25/1000, Training Loss: 0.2567998309637986\n",
      "Epoch 25/1000, Validation Loss: 0.2535534530878067\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 26/1000, Training Loss: 0.26177324033251\n",
      "Epoch 26/1000, Validation Loss: 0.24963429272174836\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 27/1000, Training Loss: 0.25001418035404355\n",
      "Epoch 27/1000, Validation Loss: 0.24802252948284148\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 28/1000, Training Loss: 0.26028693189807967\n",
      "Epoch 28/1000, Validation Loss: 0.2434697225689888\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 29/1000, Training Loss: 0.257198498821726\n",
      "Epoch 29/1000, Validation Loss: 0.24087737500667572\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 30/1000, Training Loss: 0.24917091575323366\n",
      "Epoch 30/1000, Validation Loss: 0.24392617046833037\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 31/1000, Training Loss: 0.24527688382887372\n",
      "Epoch 31/1000, Validation Loss: 0.237416610121727\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 32/1000, Training Loss: 0.23824198470980512\n",
      "Epoch 32/1000, Validation Loss: 0.23462962359189987\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 33/1000, Training Loss: 0.23646541768867596\n",
      "Epoch 33/1000, Validation Loss: 0.23293787091970444\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 34/1000, Training Loss: 0.25001450102118883\n",
      "Epoch 34/1000, Validation Loss: 0.2339135617017746\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 35/1000, Training Loss: 0.23946955464049882\n",
      "Epoch 35/1000, Validation Loss: 0.23409681320190429\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 36/1000, Training Loss: 0.23349044910248587\n",
      "Epoch 36/1000, Validation Loss: 0.23156949430704116\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 37/1000, Training Loss: 0.23068263753792087\n",
      "Epoch 37/1000, Validation Loss: 0.22818747609853746\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 38/1000, Training Loss: 0.22940358117807144\n",
      "Epoch 38/1000, Validation Loss: 0.22889100462198259\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 39/1000, Training Loss: 0.2290977813011291\n",
      "Epoch 39/1000, Validation Loss: 0.22547605633735657\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 40/1000, Training Loss: 0.22653125147974373\n",
      "Epoch 40/1000, Validation Loss: 0.224875545501709\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 41/1000, Training Loss: 0.22733017378578\n",
      "Epoch 41/1000, Validation Loss: 0.22324697077274322\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 42/1000, Training Loss: 0.22632175808151564\n",
      "Epoch 42/1000, Validation Loss: 0.22338450998067855\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 43/1000, Training Loss: 0.22481845641125212\n",
      "Epoch 43/1000, Validation Loss: 0.22035455703735352\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 44/1000, Training Loss: 0.2242311410167638\n",
      "Epoch 44/1000, Validation Loss: 0.21945905387401582\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 45/1000, Training Loss: 0.22758337621595345\n",
      "Epoch 45/1000, Validation Loss: 0.21875948458909988\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 46/1000, Training Loss: 0.2255378901666286\n",
      "Epoch 46/1000, Validation Loss: 0.21748703271150588\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 47/1000, Training Loss: 0.27507418423306707\n",
      "Epoch 47/1000, Validation Loss: 0.22243208289146424\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 48/1000, Training Loss: 0.24357342676204793\n",
      "Epoch 48/1000, Validation Loss: 0.22072192281484604\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 49/1000, Training Loss: 0.22008957341313362\n",
      "Epoch 49/1000, Validation Loss: 0.2175457939505577\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 50/1000, Training Loss: 0.22305982267739727\n",
      "Epoch 50/1000, Validation Loss: 0.22128010988235475\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 51/1000, Training Loss: 0.2220356073230505\n",
      "Epoch 51/1000, Validation Loss: 0.21733882576227187\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 52/1000, Training Loss: 0.21790998053335237\n",
      "Epoch 52/1000, Validation Loss: 0.21485989391803742\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 53/1000, Training Loss: 0.21682728682735972\n",
      "Epoch 53/1000, Validation Loss: 0.21623343527317046\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 54/1000, Training Loss: 0.2563774731813693\n",
      "Epoch 54/1000, Validation Loss: 0.22804888784885408\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 55/1000, Training Loss: 0.27662812421719235\n",
      "Epoch 55/1000, Validation Loss: 0.21278080344200134\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 56/1000, Training Loss: 0.23337722496659147\n",
      "Epoch 56/1000, Validation Loss: 0.21842145025730134\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 57/1000, Training Loss: 0.22208734484864215\n",
      "Epoch 57/1000, Validation Loss: 0.21471355110406876\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 58/1000, Training Loss: 0.2154752226162921\n",
      "Epoch 58/1000, Validation Loss: 0.21216160729527472\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 59/1000, Training Loss: 0.21742976588361404\n",
      "Epoch 59/1000, Validation Loss: 0.21090248078107834\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 60/1000, Training Loss: 0.21650736866628423\n",
      "Epoch 60/1000, Validation Loss: 0.21100422292947768\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 61/1000, Training Loss: 0.21269570836139953\n",
      "Epoch 61/1000, Validation Loss: 0.2106361620128155\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 62/1000, Training Loss: 0.21276095819969973\n",
      "Epoch 62/1000, Validation Loss: 0.21116220355033874\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 63/1000, Training Loss: 0.21319694641758413\n",
      "Epoch 63/1000, Validation Loss: 0.20878906697034835\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 64/1000, Training Loss: 0.22069944996459812\n",
      "Epoch 64/1000, Validation Loss: 0.20913821533322335\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 65/1000, Training Loss: 0.21591375695139753\n",
      "Epoch 65/1000, Validation Loss: 0.20623764321208\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 66/1000, Training Loss: 0.21229182008434744\n",
      "Epoch 66/1000, Validation Loss: 0.207537542283535\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 67/1000, Training Loss: 0.220531062606503\n",
      "Epoch 67/1000, Validation Loss: 0.20656157657504082\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 68/1000, Training Loss: 0.21836634973684946\n",
      "Epoch 68/1000, Validation Loss: 0.20847387090325356\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 69/1000, Training Loss: 0.21595722336011627\n",
      "Epoch 69/1000, Validation Loss: 0.20624351128935814\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 70/1000, Training Loss: 0.21155234513913884\n",
      "Epoch 70/1000, Validation Loss: 0.2046750769019127\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 71/1000, Training Loss: 0.2097913098393702\n",
      "Epoch 71/1000, Validation Loss: 0.20386265963315964\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 72/1000, Training Loss: 0.20790855878708409\n",
      "Epoch 72/1000, Validation Loss: 0.20413953140378\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 73/1000, Training Loss: 0.20578721428618713\n",
      "Epoch 73/1000, Validation Loss: 0.20263126045465468\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 74/1000, Training Loss: 0.20581508979347407\n",
      "Epoch 74/1000, Validation Loss: 0.202699963003397\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 75/1000, Training Loss: 0.2052831491078798\n",
      "Epoch 75/1000, Validation Loss: 0.20142989084124566\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 76/1000, Training Loss: 0.21209914573267394\n",
      "Epoch 76/1000, Validation Loss: 0.20378682687878608\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 77/1000, Training Loss: 0.20647569146810793\n",
      "Epoch 77/1000, Validation Loss: 0.2017759695649147\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 78/1000, Training Loss: 0.21082861706906675\n",
      "Epoch 78/1000, Validation Loss: 0.20323925465345383\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 79/1000, Training Loss: 0.2390009747708545\n",
      "Epoch 79/1000, Validation Loss: 0.20252929180860518\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 80/1000, Training Loss: 0.2084748029124503\n",
      "Epoch 80/1000, Validation Loss: 0.20413051769137383\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 81/1000, Training Loss: 0.20862271768205307\n",
      "Epoch 81/1000, Validation Loss: 0.20341195166110992\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 82/1000, Training Loss: 0.2011044306621211\n",
      "Epoch 82/1000, Validation Loss: 0.19874008223414422\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 83/1000, Training Loss: 0.20409784013149784\n",
      "Epoch 83/1000, Validation Loss: 0.20136742070317268\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 84/1000, Training Loss: 0.20492617771321653\n",
      "Epoch 84/1000, Validation Loss: 0.1999911315739155\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 85/1000, Training Loss: 0.20735585368147083\n",
      "Epoch 85/1000, Validation Loss: 0.19740667939186096\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 86/1000, Training Loss: 0.200347095016874\n",
      "Epoch 86/1000, Validation Loss: 0.19619259461760521\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 87/1000, Training Loss: 0.21395230278664945\n",
      "Epoch 87/1000, Validation Loss: 0.19674377217888833\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 88/1000, Training Loss: 0.2214408731635879\n",
      "Epoch 88/1000, Validation Loss: 0.20599365830421448\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 89/1000, Training Loss: 0.20684116366593278\n",
      "Epoch 89/1000, Validation Loss: 0.19717291817069055\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 90/1000, Training Loss: 0.1993282681294516\n",
      "Epoch 90/1000, Validation Loss: 0.1960119366645813\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 91/1000, Training Loss: 0.196511748520767\n",
      "Epoch 91/1000, Validation Loss: 0.19643191173672675\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 92/1000, Training Loss: 0.20171065701573504\n",
      "Epoch 92/1000, Validation Loss: 0.19768662750720978\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 93/1000, Training Loss: 0.20459374843859204\n",
      "Epoch 93/1000, Validation Loss: 0.19761317744851112\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 94/1000, Training Loss: 0.20111742192039303\n",
      "Epoch 94/1000, Validation Loss: 0.19605463221669198\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 95/1000, Training Loss: 0.19980877316465565\n",
      "Epoch 95/1000, Validation Loss: 0.19632061421871186\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 96/1000, Training Loss: 0.19948257315976947\n",
      "Epoch 96/1000, Validation Loss: 0.19534967094659805\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 97/1000, Training Loss: 0.19462482449050775\n",
      "Epoch 97/1000, Validation Loss: 0.194120105355978\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 98/1000, Training Loss: 0.19341946944055677\n",
      "Epoch 98/1000, Validation Loss: 0.19310617297887803\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 99/1000, Training Loss: 0.2082132121511534\n",
      "Epoch 99/1000, Validation Loss: 0.19278061538934707\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 100/1000, Training Loss: 0.19706346255307103\n",
      "Epoch 100/1000, Validation Loss: 0.19447557553648948\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 101/1000, Training Loss: 0.19169725289604828\n",
      "Epoch 101/1000, Validation Loss: 0.19364086166024208\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 102/1000, Training Loss: 0.19733496375528037\n",
      "Epoch 102/1000, Validation Loss: 0.19400424957275392\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 103/1000, Training Loss: 0.1933385703493567\n",
      "Epoch 103/1000, Validation Loss: 0.19361073821783065\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 104/1000, Training Loss: 0.1905248980380266\n",
      "Epoch 104/1000, Validation Loss: 0.19300888180732728\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 105/1000, Training Loss: 0.19091561400130683\n",
      "Epoch 105/1000, Validation Loss: 0.1907023683190346\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 106/1000, Training Loss: 0.19121332159813711\n",
      "Epoch 106/1000, Validation Loss: 0.18969113007187843\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 107/1000, Training Loss: 0.1930256047669579\n",
      "Epoch 107/1000, Validation Loss: 0.1899988129734993\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 108/1000, Training Loss: 0.20240771229944976\n",
      "Epoch 108/1000, Validation Loss: 0.19272638559341432\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 109/1000, Training Loss: 0.19250921539359672\n",
      "Epoch 109/1000, Validation Loss: 0.18835856765508652\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 110/1000, Training Loss: 0.18736670946807363\n",
      "Epoch 110/1000, Validation Loss: 0.19185752421617508\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 111/1000, Training Loss: 0.18679515811085118\n",
      "Epoch 111/1000, Validation Loss: 0.1912822790443897\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 112/1000, Training Loss: 0.19051457649352505\n",
      "Epoch 112/1000, Validation Loss: 0.1880891889333725\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 113/1000, Training Loss: 0.18611816562000005\n",
      "Epoch 113/1000, Validation Loss: 0.1863154575228691\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 114/1000, Training Loss: 0.18706324316707312\n",
      "Epoch 114/1000, Validation Loss: 0.18608315661549568\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 115/1000, Training Loss: 0.18830503055862352\n",
      "Epoch 115/1000, Validation Loss: 0.18597779273986817\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 116/1000, Training Loss: 0.20334840244522281\n",
      "Epoch 116/1000, Validation Loss: 0.19043435528874397\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 117/1000, Training Loss: 0.19576582562762732\n",
      "Epoch 117/1000, Validation Loss: 0.18486673459410669\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 118/1000, Training Loss: 0.18517992798896396\n",
      "Epoch 118/1000, Validation Loss: 0.18478627428412436\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 119/1000, Training Loss: 0.1831756147930362\n",
      "Epoch 119/1000, Validation Loss: 0.1840298943221569\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 120/1000, Training Loss: 0.18305951901072381\n",
      "Epoch 120/1000, Validation Loss: 0.1846793368458748\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 121/1000, Training Loss: 0.18290784994828488\n",
      "Epoch 121/1000, Validation Loss: 0.18300384730100633\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 122/1000, Training Loss: 0.18380201739423416\n",
      "Epoch 122/1000, Validation Loss: 0.1831173337996006\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 123/1000, Training Loss: 0.18192457630499906\n",
      "Epoch 123/1000, Validation Loss: 0.18327749520540237\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 124/1000, Training Loss: 0.18106650387612627\n",
      "Epoch 124/1000, Validation Loss: 0.1841660961508751\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 125/1000, Training Loss: 0.18936118761114046\n",
      "Epoch 125/1000, Validation Loss: 0.18496388867497443\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 126/1000, Training Loss: 0.1937366103132566\n",
      "Epoch 126/1000, Validation Loss: 0.18340186402201653\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 127/1000, Training Loss: 0.18440644917827026\n",
      "Epoch 127/1000, Validation Loss: 0.1825089506804943\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 128/1000, Training Loss: 0.18157832207632998\n",
      "Epoch 128/1000, Validation Loss: 0.18130097091197966\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 129/1000, Training Loss: 0.18607890123830123\n",
      "Epoch 129/1000, Validation Loss: 0.1853533588349819\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 130/1000, Training Loss: 0.1849270634280116\n",
      "Epoch 130/1000, Validation Loss: 0.18326957523822784\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 131/1000, Training Loss: 0.18183206927542592\n",
      "Epoch 131/1000, Validation Loss: 0.18147207647562028\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 132/1000, Training Loss: 0.17906300371567554\n",
      "Epoch 132/1000, Validation Loss: 0.1801234908401966\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 133/1000, Training Loss: 0.1778972393687011\n",
      "Epoch 133/1000, Validation Loss: 0.18289500176906587\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 134/1000, Training Loss: 0.1795418557583117\n",
      "Epoch 134/1000, Validation Loss: 0.17951595708727835\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 135/1000, Training Loss: 0.17726460670518482\n",
      "Epoch 135/1000, Validation Loss: 0.17959025204181672\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 136/1000, Training Loss: 0.17694221206885927\n",
      "Epoch 136/1000, Validation Loss: 0.1785036765038967\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 137/1000, Training Loss: 0.17658491097002602\n",
      "Epoch 137/1000, Validation Loss: 0.178180992603302\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 138/1000, Training Loss: 0.17565540806846877\n",
      "Epoch 138/1000, Validation Loss: 0.1781560719013214\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 139/1000, Training Loss: 0.18469316468519323\n",
      "Epoch 139/1000, Validation Loss: 0.1785578601062298\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 140/1000, Training Loss: 0.1843242589749542\n",
      "Epoch 140/1000, Validation Loss: 0.1784130558371544\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 141/1000, Training Loss: 0.21416514746698678\n",
      "Epoch 141/1000, Validation Loss: 0.18016789108514786\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 142/1000, Training Loss: 0.20805001580247692\n",
      "Epoch 142/1000, Validation Loss: 0.17696611285209657\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 143/1000, Training Loss: 0.1816230858950054\n",
      "Epoch 143/1000, Validation Loss: 0.17932583764195442\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 144/1000, Training Loss: 0.17514601152609377\n",
      "Epoch 144/1000, Validation Loss: 0.17894682809710502\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 145/1000, Training Loss: 0.1767927298651022\n",
      "Epoch 145/1000, Validation Loss: 0.17687839940190314\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 146/1000, Training Loss: 0.1728967057321878\n",
      "Epoch 146/1000, Validation Loss: 0.17814452424645424\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 147/1000, Training Loss: 0.17213628194340522\n",
      "Epoch 147/1000, Validation Loss: 0.17564447447657586\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 148/1000, Training Loss: 0.17255278525294224\n",
      "Epoch 148/1000, Validation Loss: 0.17520731762051583\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 149/1000, Training Loss: 0.17176092047171265\n",
      "Epoch 149/1000, Validation Loss: 0.17484918087720872\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 150/1000, Training Loss: 0.1779203610677345\n",
      "Epoch 150/1000, Validation Loss: 0.17468493357300757\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 151/1000, Training Loss: 0.177304312878964\n",
      "Epoch 151/1000, Validation Loss: 0.17245472446084023\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 152/1000, Training Loss: 0.17227443030067519\n",
      "Epoch 152/1000, Validation Loss: 0.17328591048717498\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 153/1000, Training Loss: 0.1736356114201686\n",
      "Epoch 153/1000, Validation Loss: 0.17271388918161393\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 154/1000, Training Loss: 0.17058154460334896\n",
      "Epoch 154/1000, Validation Loss: 0.1811615988612175\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 155/1000, Training Loss: 0.17058306766272174\n",
      "Epoch 155/1000, Validation Loss: 0.17282647863030434\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 156/1000, Training Loss: 0.1693524374243091\n",
      "Epoch 156/1000, Validation Loss: 0.1734768345952034\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 157/1000, Training Loss: 0.21237174143978194\n",
      "Epoch 157/1000, Validation Loss: 0.1733161062002182\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 158/1000, Training Loss: 0.18401472247662207\n",
      "Epoch 158/1000, Validation Loss: 0.17362498566508294\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 159/1000, Training Loss: 0.1685582422411672\n",
      "Epoch 159/1000, Validation Loss: 0.17195545583963395\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 160/1000, Training Loss: 0.17084653135023864\n",
      "Epoch 160/1000, Validation Loss: 0.17125497609376908\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 161/1000, Training Loss: 0.1665229504932558\n",
      "Epoch 161/1000, Validation Loss: 0.17152727991342545\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 162/1000, Training Loss: 0.1663838416547971\n",
      "Epoch 162/1000, Validation Loss: 0.17370883449912072\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 163/1000, Training Loss: 0.16611185776727164\n",
      "Epoch 163/1000, Validation Loss: 0.17543346136808396\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 164/1000, Training Loss: 0.16708621996290543\n",
      "Epoch 164/1000, Validation Loss: 0.17007715329527856\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 165/1000, Training Loss: 0.16522805127954365\n",
      "Epoch 165/1000, Validation Loss: 0.17035451903939247\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 166/1000, Training Loss: 0.16635480554153523\n",
      "Epoch 166/1000, Validation Loss: 0.16995580941438676\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 167/1000, Training Loss: 0.16402343031265498\n",
      "Epoch 167/1000, Validation Loss: 0.1691455662250519\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 168/1000, Training Loss: 0.18515013581981846\n",
      "Epoch 168/1000, Validation Loss: 0.16909747645258905\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 169/1000, Training Loss: 0.170981280654636\n",
      "Epoch 169/1000, Validation Loss: 0.17155233919620513\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 170/1000, Training Loss: 0.1853178527717497\n",
      "Epoch 170/1000, Validation Loss: 0.17113018333911895\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 171/1000, Training Loss: 0.1702500895332253\n",
      "Epoch 171/1000, Validation Loss: 0.1712485171854496\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 172/1000, Training Loss: 0.16280338678088987\n",
      "Epoch 172/1000, Validation Loss: 0.17160825654864312\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 173/1000, Training Loss: 0.16310507467235713\n",
      "Epoch 173/1000, Validation Loss: 0.1690860204398632\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 174/1000, Training Loss: 0.16184271339215248\n",
      "Epoch 174/1000, Validation Loss: 0.16807360649108888\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 175/1000, Training Loss: 0.16093176130579748\n",
      "Epoch 175/1000, Validation Loss: 0.1677984967827797\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 176/1000, Training Loss: 0.16050550823777432\n",
      "Epoch 176/1000, Validation Loss: 0.16707276776432992\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 177/1000, Training Loss: 0.16164183923426798\n",
      "Epoch 177/1000, Validation Loss: 0.1703271210193634\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 178/1000, Training Loss: 0.16129129799995937\n",
      "Epoch 178/1000, Validation Loss: 0.16669293493032455\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 179/1000, Training Loss: 0.16052829795608334\n",
      "Epoch 179/1000, Validation Loss: 0.16619908660650254\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 180/1000, Training Loss: 0.1594497529680238\n",
      "Epoch 180/1000, Validation Loss: 0.16672645136713982\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 181/1000, Training Loss: 0.16724090782158516\n",
      "Epoch 181/1000, Validation Loss: 0.16723539382219316\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 182/1000, Training Loss: 0.16211659008429563\n",
      "Epoch 182/1000, Validation Loss: 0.16704170107841493\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 183/1000, Training Loss: 0.15889503552584666\n",
      "Epoch 183/1000, Validation Loss: 0.16810383051633834\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 184/1000, Training Loss: 0.16032973749964846\n",
      "Epoch 184/1000, Validation Loss: 0.16576906964182853\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 185/1000, Training Loss: 0.16144765562870922\n",
      "Epoch 185/1000, Validation Loss: 0.1653526782989502\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 186/1000, Training Loss: 0.16966735177180348\n",
      "Epoch 186/1000, Validation Loss: 0.1697474606335163\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 187/1000, Training Loss: 0.16801594636019537\n",
      "Epoch 187/1000, Validation Loss: 0.16641682758927345\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 188/1000, Training Loss: 0.1572653540209986\n",
      "Epoch 188/1000, Validation Loss: 0.16470169201493262\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 189/1000, Training Loss: 0.15610472969802133\n",
      "Epoch 189/1000, Validation Loss: 0.16790317595005036\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 190/1000, Training Loss: 0.1572384864420575\n",
      "Epoch 190/1000, Validation Loss: 0.16538856253027917\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 191/1000, Training Loss: 0.15589687547774292\n",
      "Epoch 191/1000, Validation Loss: 0.16423401087522507\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 192/1000, Training Loss: 0.15501615751118686\n",
      "Epoch 192/1000, Validation Loss: 0.1647216260433197\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 193/1000, Training Loss: 0.1553085870383417\n",
      "Epoch 193/1000, Validation Loss: 0.16280733942985534\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 194/1000, Training Loss: 0.15455096571103616\n",
      "Epoch 194/1000, Validation Loss: 0.16300803571939468\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 195/1000, Training Loss: 0.1540747674355539\n",
      "Epoch 195/1000, Validation Loss: 0.16234620213508605\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 196/1000, Training Loss: 0.15400016863134391\n",
      "Epoch 196/1000, Validation Loss: 0.16256908029317857\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 197/1000, Training Loss: 0.15630378230821854\n",
      "Epoch 197/1000, Validation Loss: 0.16231102570891381\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 198/1000, Training Loss: 0.15362410929382725\n",
      "Epoch 198/1000, Validation Loss: 0.16429632902145386\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 199/1000, Training Loss: 0.15320866749229312\n",
      "Epoch 199/1000, Validation Loss: 0.16235012859106063\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 200/1000, Training Loss: 0.15274189507552222\n",
      "Epoch 200/1000, Validation Loss: 0.16183137148618698\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 201/1000, Training Loss: 0.15283586219975762\n",
      "Epoch 201/1000, Validation Loss: 0.1641920894384384\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 202/1000, Training Loss: 0.15412893219321383\n",
      "Epoch 202/1000, Validation Loss: 0.16125859767198564\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 203/1000, Training Loss: 0.15212461211052083\n",
      "Epoch 203/1000, Validation Loss: 0.16094456911087035\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 204/1000, Training Loss: 0.1512726944939798\n",
      "Epoch 204/1000, Validation Loss: 0.1607178881764412\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 205/1000, Training Loss: 0.150924348254122\n",
      "Epoch 205/1000, Validation Loss: 0.16032355055212974\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 206/1000, Training Loss: 0.15080642566888355\n",
      "Epoch 206/1000, Validation Loss: 0.16061500757932662\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 207/1000, Training Loss: 0.16400669215648783\n",
      "Epoch 207/1000, Validation Loss: 0.16284252628684043\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 208/1000, Training Loss: 0.16004394286987828\n",
      "Epoch 208/1000, Validation Loss: 0.16181428134441375\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 209/1000, Training Loss: 0.16741330351899653\n",
      "Epoch 209/1000, Validation Loss: 0.16489719450473786\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 210/1000, Training Loss: 0.1658327062163438\n",
      "Epoch 210/1000, Validation Loss: 0.16186946481466294\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 211/1000, Training Loss: 0.1514833033377049\n",
      "Epoch 211/1000, Validation Loss: 0.159682397544384\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 212/1000, Training Loss: 0.15094250550164895\n",
      "Epoch 212/1000, Validation Loss: 0.16074516475200654\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 213/1000, Training Loss: 0.1491610123501981\n",
      "Epoch 213/1000, Validation Loss: 0.1600039154291153\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 214/1000, Training Loss: 0.14867803531096263\n",
      "Epoch 214/1000, Validation Loss: 0.15989862754940987\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 215/1000, Training Loss: 0.14781549209546224\n",
      "Epoch 215/1000, Validation Loss: 0.1589151382446289\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 216/1000, Training Loss: 0.14802531773845354\n",
      "Epoch 216/1000, Validation Loss: 0.15966110303997993\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 217/1000, Training Loss: 0.1510335604349772\n",
      "Epoch 217/1000, Validation Loss: 0.16402868181467056\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 218/1000, Training Loss: 0.15672690669695535\n",
      "Epoch 218/1000, Validation Loss: 0.15951134636998177\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 219/1000, Training Loss: 0.1715630843651061\n",
      "Epoch 219/1000, Validation Loss: 0.1707288570702076\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 220/1000, Training Loss: 0.1711180500124636\n",
      "Epoch 220/1000, Validation Loss: 0.15889013931155205\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 221/1000, Training Loss: 0.15344942507206225\n",
      "Epoch 221/1000, Validation Loss: 0.15943018794059755\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 222/1000, Training Loss: 0.1479927620113777\n",
      "Epoch 222/1000, Validation Loss: 0.1596490129828453\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 223/1000, Training Loss: 0.14607980986372293\n",
      "Epoch 223/1000, Validation Loss: 0.1592292994260788\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 224/1000, Training Loss: 0.14537051480774785\n",
      "Epoch 224/1000, Validation Loss: 0.1597132168710232\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 225/1000, Training Loss: 0.14549214202983707\n",
      "Epoch 225/1000, Validation Loss: 0.15923614501953126\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 226/1000, Training Loss: 0.145345975444013\n",
      "Epoch 226/1000, Validation Loss: 0.16290636584162713\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 227/1000, Training Loss: 0.1512976491860315\n",
      "Epoch 227/1000, Validation Loss: 0.16044943556189536\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 228/1000, Training Loss: 0.14870874309631557\n",
      "Epoch 228/1000, Validation Loss: 0.15868769139051436\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 229/1000, Training Loss: 0.15671098853151003\n",
      "Epoch 229/1000, Validation Loss: 0.15790550783276558\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 230/1000, Training Loss: 0.152560178373082\n",
      "Epoch 230/1000, Validation Loss: 0.15907348021864892\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 231/1000, Training Loss: 0.1439005525092255\n",
      "Epoch 231/1000, Validation Loss: 0.1569725900888443\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 232/1000, Training Loss: 0.14518995027916104\n",
      "Epoch 232/1000, Validation Loss: 0.16104764714837075\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 233/1000, Training Loss: 0.14680092485037213\n",
      "Epoch 233/1000, Validation Loss: 0.16162235736846925\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 234/1000, Training Loss: 0.14278901794779242\n",
      "Epoch 234/1000, Validation Loss: 0.15749351009726525\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 235/1000, Training Loss: 0.14218955994674973\n",
      "Epoch 235/1000, Validation Loss: 0.1568027190864086\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 236/1000, Training Loss: 0.14201092877192423\n",
      "Epoch 236/1000, Validation Loss: 0.16069584339857101\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 237/1000, Training Loss: 0.14108598532495273\n",
      "Epoch 237/1000, Validation Loss: 0.15735798105597495\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 238/1000, Training Loss: 0.1416152017944328\n",
      "Epoch 238/1000, Validation Loss: 0.1625683806836605\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 239/1000, Training Loss: 0.14186511882677028\n",
      "Epoch 239/1000, Validation Loss: 0.15944891422986984\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 240/1000, Training Loss: 0.14124466151948653\n",
      "Epoch 240/1000, Validation Loss: 0.15733409374952317\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 241/1000, Training Loss: 0.1407526604119031\n",
      "Epoch 241/1000, Validation Loss: 0.15730093121528627\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 242/1000, Training Loss: 0.14085096870115318\n",
      "Epoch 242/1000, Validation Loss: 0.15696335583925247\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 243/1000, Training Loss: 0.14048063187111243\n",
      "Epoch 243/1000, Validation Loss: 0.15596284866333007\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 244/1000, Training Loss: 0.13969757503775113\n",
      "Epoch 244/1000, Validation Loss: 0.1558010533452034\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 245/1000, Training Loss: 0.14044024525295148\n",
      "Epoch 245/1000, Validation Loss: 0.1600877784192562\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 246/1000, Training Loss: 0.14094475443091461\n",
      "Epoch 246/1000, Validation Loss: 0.1578359156847\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 247/1000, Training Loss: 0.13972713111569665\n",
      "Epoch 247/1000, Validation Loss: 0.1561319887638092\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 248/1000, Training Loss: 0.1394028731178967\n",
      "Epoch 248/1000, Validation Loss: 0.15459533780813217\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 249/1000, Training Loss: 0.13845875705886762\n",
      "Epoch 249/1000, Validation Loss: 0.155155186355114\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 250/1000, Training Loss: 0.13835871688263746\n",
      "Epoch 250/1000, Validation Loss: 0.15432449504733087\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 251/1000, Training Loss: 0.1379971977177204\n",
      "Epoch 251/1000, Validation Loss: 0.1544874392449856\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 252/1000, Training Loss: 0.13897244409913673\n",
      "Epoch 252/1000, Validation Loss: 0.15443557798862456\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 253/1000, Training Loss: 0.13849917380538695\n",
      "Epoch 253/1000, Validation Loss: 0.15470099225640296\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 254/1000, Training Loss: 0.14682691310550652\n",
      "Epoch 254/1000, Validation Loss: 0.16042810082435607\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 255/1000, Training Loss: 0.1409414549193838\n",
      "Epoch 255/1000, Validation Loss: 0.15443242862820625\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 256/1000, Training Loss: 0.13832515982657617\n",
      "Epoch 256/1000, Validation Loss: 0.15435122922062874\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 257/1000, Training Loss: 0.13783951909800973\n",
      "Epoch 257/1000, Validation Loss: 0.15445692092180252\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 258/1000, Training Loss: 0.14078007273229898\n",
      "Epoch 258/1000, Validation Loss: 0.15579143911600113\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 259/1000, Training Loss: 0.1378552145689872\n",
      "Epoch 259/1000, Validation Loss: 0.15423850789666177\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 260/1000, Training Loss: 0.13667867772335954\n",
      "Epoch 260/1000, Validation Loss: 0.1551404058933258\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 261/1000, Training Loss: 0.14232180362530783\n",
      "Epoch 261/1000, Validation Loss: 0.1535498671233654\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 262/1000, Training Loss: 0.13923776777935962\n",
      "Epoch 262/1000, Validation Loss: 0.1647414520382881\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 263/1000, Training Loss: 0.14435027831909703\n",
      "Epoch 263/1000, Validation Loss: 0.15370099246501923\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 264/1000, Training Loss: 0.13650501272915042\n",
      "Epoch 264/1000, Validation Loss: 0.1582809306681156\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 265/1000, Training Loss: 0.1384780742236591\n",
      "Epoch 265/1000, Validation Loss: 0.1545126460492611\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 266/1000, Training Loss: 0.13571509711176738\n",
      "Epoch 266/1000, Validation Loss: 0.15303630977869034\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 267/1000, Training Loss: 0.14597131582159623\n",
      "Epoch 267/1000, Validation Loss: 0.1534033462405205\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 268/1000, Training Loss: 0.14174910471917304\n",
      "Epoch 268/1000, Validation Loss: 0.15673083290457726\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 269/1000, Training Loss: 0.13462655457289086\n",
      "Epoch 269/1000, Validation Loss: 0.15510681942105292\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 270/1000, Training Loss: 0.13443526068437553\n",
      "Epoch 270/1000, Validation Loss: 0.1551348328590393\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 271/1000, Training Loss: 0.13477412997276678\n",
      "Epoch 271/1000, Validation Loss: 0.15214861929416656\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 272/1000, Training Loss: 0.13417617902707527\n",
      "Epoch 272/1000, Validation Loss: 0.15227709263563155\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 273/1000, Training Loss: 0.1407102559711419\n",
      "Epoch 273/1000, Validation Loss: 0.15139196962118148\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 274/1000, Training Loss: 0.1341082986196567\n",
      "Epoch 274/1000, Validation Loss: 0.153277587890625\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 275/1000, Training Loss: 0.13311151612525268\n",
      "Epoch 275/1000, Validation Loss: 0.15179260820150375\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 276/1000, Training Loss: 0.13281852167619054\n",
      "Epoch 276/1000, Validation Loss: 0.15239288434386253\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 277/1000, Training Loss: 0.1325373404170647\n",
      "Epoch 277/1000, Validation Loss: 0.15137733817100524\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 278/1000, Training Loss: 0.13215642071822667\n",
      "Epoch 278/1000, Validation Loss: 0.150738637894392\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 279/1000, Training Loss: 0.13173117013260102\n",
      "Epoch 279/1000, Validation Loss: 0.15116966068744658\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 280/1000, Training Loss: 0.1319175299037961\n",
      "Epoch 280/1000, Validation Loss: 0.1517657868564129\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 281/1000, Training Loss: 0.13166082091629505\n",
      "Epoch 281/1000, Validation Loss: 0.15248540043830872\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 282/1000, Training Loss: 0.13271740921717376\n",
      "Epoch 282/1000, Validation Loss: 0.15832617804408072\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 283/1000, Training Loss: 0.13210414152811556\n",
      "Epoch 283/1000, Validation Loss: 0.15212487056851387\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 284/1000, Training Loss: 0.13246578796693653\n",
      "Epoch 284/1000, Validation Loss: 0.15100891888141632\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 285/1000, Training Loss: 0.13091859973990402\n",
      "Epoch 285/1000, Validation Loss: 0.150334994494915\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 286/1000, Training Loss: 0.13146462313393475\n",
      "Epoch 286/1000, Validation Loss: 0.1507949151098728\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 287/1000, Training Loss: 0.14005070325790667\n",
      "Epoch 287/1000, Validation Loss: 0.14980073645710945\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 288/1000, Training Loss: 0.14215523325930568\n",
      "Epoch 288/1000, Validation Loss: 0.14907644875347614\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 289/1000, Training Loss: 0.1299057666340149\n",
      "Epoch 289/1000, Validation Loss: 0.15182497017085553\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 290/1000, Training Loss: 0.13173304680807918\n",
      "Epoch 290/1000, Validation Loss: 0.15166966915130614\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 291/1000, Training Loss: 0.12975817397419437\n",
      "Epoch 291/1000, Validation Loss: 0.14964906945824624\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 292/1000, Training Loss: 0.13021763761107827\n",
      "Epoch 292/1000, Validation Loss: 0.15549695566296579\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 293/1000, Training Loss: 0.13073338845781252\n",
      "Epoch 293/1000, Validation Loss: 0.15299894735217096\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 294/1000, Training Loss: 0.12856172575323166\n",
      "Epoch 294/1000, Validation Loss: 0.14962931275367736\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 295/1000, Training Loss: 0.1286796251307333\n",
      "Epoch 295/1000, Validation Loss: 0.15259527042508125\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 296/1000, Training Loss: 0.12878604824015616\n",
      "Epoch 296/1000, Validation Loss: 0.14972473978996276\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 297/1000, Training Loss: 0.12875598245598524\n",
      "Epoch 297/1000, Validation Loss: 0.15029088407754898\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 298/1000, Training Loss: 0.12797857240566016\n",
      "Epoch 298/1000, Validation Loss: 0.15264836624264716\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 299/1000, Training Loss: 0.13148790723918116\n",
      "Epoch 299/1000, Validation Loss: 0.14983708113431932\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 300/1000, Training Loss: 0.13241246802841916\n",
      "Epoch 300/1000, Validation Loss: 0.15735409408807755\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 301/1000, Training Loss: 0.1336765275562214\n",
      "Epoch 301/1000, Validation Loss: 0.15075267106294632\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 302/1000, Training Loss: 0.12775492470930605\n",
      "Epoch 302/1000, Validation Loss: 0.15291325971484185\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 303/1000, Training Loss: 0.12717662211745098\n",
      "Epoch 303/1000, Validation Loss: 0.1556632898747921\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 304/1000, Training Loss: 0.13147671177398926\n",
      "Epoch 304/1000, Validation Loss: 0.14953008741140367\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 305/1000, Training Loss: 0.12786127673119635\n",
      "Epoch 305/1000, Validation Loss: 0.15093542858958245\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 306/1000, Training Loss: 0.12642700543145502\n",
      "Epoch 306/1000, Validation Loss: 0.14946070015430452\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 307/1000, Training Loss: 0.12669521031499492\n",
      "Epoch 307/1000, Validation Loss: 0.15408831387758254\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 308/1000, Training Loss: 0.1263582480012213\n",
      "Epoch 308/1000, Validation Loss: 0.14959273412823676\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 309/1000, Training Loss: 0.12591708525467446\n",
      "Epoch 309/1000, Validation Loss: 0.1512748345732689\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 310/1000, Training Loss: 0.1272807082928279\n",
      "Epoch 310/1000, Validation Loss: 0.14901989474892616\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 311/1000, Training Loss: 0.1253619938221413\n",
      "Epoch 311/1000, Validation Loss: 0.14840808138251305\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 312/1000, Training Loss: 0.13021105118826323\n",
      "Epoch 312/1000, Validation Loss: 0.15501396507024764\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 313/1000, Training Loss: 0.15170232520676127\n",
      "Epoch 313/1000, Validation Loss: 0.14923104867339135\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 314/1000, Training Loss: 0.1306536548871401\n",
      "Epoch 314/1000, Validation Loss: 0.1501624569296837\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 315/1000, Training Loss: 0.13256292695216104\n",
      "Epoch 315/1000, Validation Loss: 0.1511286236345768\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 316/1000, Training Loss: 0.13176945167452134\n",
      "Epoch 316/1000, Validation Loss: 0.14728486388921738\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 317/1000, Training Loss: 0.12609648084103622\n",
      "Epoch 317/1000, Validation Loss: 0.1482359141111374\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 318/1000, Training Loss: 0.12529925714468346\n",
      "Epoch 318/1000, Validation Loss: 0.148004437237978\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 319/1000, Training Loss: 0.13731816440236336\n",
      "Epoch 319/1000, Validation Loss: 0.14855793118476868\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 320/1000, Training Loss: 0.14347994159543884\n",
      "Epoch 320/1000, Validation Loss: 0.14916542470455169\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 321/1000, Training Loss: 0.1245812565495155\n",
      "Epoch 321/1000, Validation Loss: 0.14724177420139312\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 322/1000, Training Loss: 0.12421844198423385\n",
      "Epoch 322/1000, Validation Loss: 0.14681629091501236\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 323/1000, Training Loss: 0.1589385555947528\n",
      "Epoch 323/1000, Validation Loss: 0.15128466337919236\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 324/1000, Training Loss: 0.1269646840547805\n",
      "Epoch 324/1000, Validation Loss: 0.14686123579740523\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 325/1000, Training Loss: 0.12421611487811521\n",
      "Epoch 325/1000, Validation Loss: 0.15073424130678176\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 326/1000, Training Loss: 0.12400840277505089\n",
      "Epoch 326/1000, Validation Loss: 0.147982157766819\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 327/1000, Training Loss: 0.12831403081323586\n",
      "Epoch 327/1000, Validation Loss: 0.14747894145548343\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 328/1000, Training Loss: 0.1755072238544623\n",
      "Epoch 328/1000, Validation Loss: 0.15295694917440414\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 329/1000, Training Loss: 0.14171434120804655\n",
      "Epoch 329/1000, Validation Loss: 0.14863837659358978\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 330/1000, Training Loss: 0.1251022435140376\n",
      "Epoch 330/1000, Validation Loss: 0.1478990253061056\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 331/1000, Training Loss: 0.12282136425503767\n",
      "Epoch 331/1000, Validation Loss: 0.1498684488236904\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 332/1000, Training Loss: 0.12222085265011629\n",
      "Epoch 332/1000, Validation Loss: 0.14749267548322678\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 333/1000, Training Loss: 0.12232193810979755\n",
      "Epoch 333/1000, Validation Loss: 0.14746278822422026\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 334/1000, Training Loss: 0.12193426283478152\n",
      "Epoch 334/1000, Validation Loss: 0.14710329994559287\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 335/1000, Training Loss: 0.12405563540318433\n",
      "Epoch 335/1000, Validation Loss: 0.15010724738240241\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 336/1000, Training Loss: 0.12186171129056834\n",
      "Epoch 336/1000, Validation Loss: 0.14709740579128266\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 337/1000, Training Loss: 0.12125317592119031\n",
      "Epoch 337/1000, Validation Loss: 0.1475825399160385\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 338/1000, Training Loss: 0.12503543174734302\n",
      "Epoch 338/1000, Validation Loss: 0.14773191325366497\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 339/1000, Training Loss: 0.12174916888276764\n",
      "Epoch 339/1000, Validation Loss: 0.1475969597697258\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 340/1000, Training Loss: 0.12132948076389\n",
      "Epoch 340/1000, Validation Loss: 0.14890215173363686\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 341/1000, Training Loss: 0.127128581863408\n",
      "Epoch 341/1000, Validation Loss: 0.1482048973441124\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 342/1000, Training Loss: 0.12966659022312763\n",
      "Epoch 342/1000, Validation Loss: 0.15424264892935752\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 343/1000, Training Loss: 0.12035520513806357\n",
      "Epoch 343/1000, Validation Loss: 0.14728226102888584\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 344/1000, Training Loss: 0.1210395500940435\n",
      "Epoch 344/1000, Validation Loss: 0.1472752645611763\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 345/1000, Training Loss: 0.1533138783392953\n",
      "Epoch 345/1000, Validation Loss: 0.14668293669819832\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 346/1000, Training Loss: 0.12498751764788375\n",
      "Epoch 346/1000, Validation Loss: 0.15100962072610855\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 347/1000, Training Loss: 0.1268341763346803\n",
      "Epoch 347/1000, Validation Loss: 0.1594521902501583\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 348/1000, Training Loss: 0.13196724331846424\n",
      "Epoch 348/1000, Validation Loss: 0.14964393824338912\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 349/1000, Training Loss: 0.13060553123553595\n",
      "Epoch 349/1000, Validation Loss: 0.14885464385151864\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 350/1000, Training Loss: 0.12279267171306499\n",
      "Epoch 350/1000, Validation Loss: 0.14859261624515058\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 351/1000, Training Loss: 0.11995455788165404\n",
      "Epoch 351/1000, Validation Loss: 0.14666352458298207\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 352/1000, Training Loss: 0.11926914583526434\n",
      "Epoch 352/1000, Validation Loss: 0.14678726010024548\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 353/1000, Training Loss: 0.11908840739206604\n",
      "Epoch 353/1000, Validation Loss: 0.1464469276368618\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 354/1000, Training Loss: 0.12114311615918197\n",
      "Epoch 354/1000, Validation Loss: 0.14735901765525342\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 355/1000, Training Loss: 0.12181958205559675\n",
      "Epoch 355/1000, Validation Loss: 0.14701440930366516\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 356/1000, Training Loss: 0.12005407460431645\n",
      "Epoch 356/1000, Validation Loss: 0.14767083749175072\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 357/1000, Training Loss: 0.1195237957233313\n",
      "Epoch 357/1000, Validation Loss: 0.14797941520810126\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 358/1000, Training Loss: 0.11888686867055809\n",
      "Epoch 358/1000, Validation Loss: 0.14808044359087943\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 359/1000, Training Loss: 0.11975553317689429\n",
      "Epoch 359/1000, Validation Loss: 0.14676858335733414\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 360/1000, Training Loss: 0.11775751329853437\n",
      "Epoch 360/1000, Validation Loss: 0.14836879223585128\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 361/1000, Training Loss: 0.11803421946059839\n",
      "Epoch 361/1000, Validation Loss: 0.14619427509605884\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 362/1000, Training Loss: 0.11844290660833483\n",
      "Epoch 362/1000, Validation Loss: 0.1466349571943283\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 363/1000, Training Loss: 0.11757298182826215\n",
      "Epoch 363/1000, Validation Loss: 0.15153338089585305\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 364/1000, Training Loss: 0.11827916330566593\n",
      "Epoch 364/1000, Validation Loss: 0.14880157373845576\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 365/1000, Training Loss: 0.11856444848372656\n",
      "Epoch 365/1000, Validation Loss: 0.1468481846153736\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 366/1000, Training Loss: 0.13178816233195512\n",
      "Epoch 366/1000, Validation Loss: 0.1466046802699566\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 367/1000, Training Loss: 0.12463582599312027\n",
      "Epoch 367/1000, Validation Loss: 0.14907087236642838\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 368/1000, Training Loss: 0.11960735062465976\n",
      "Epoch 368/1000, Validation Loss: 0.14709290638566017\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 369/1000, Training Loss: 0.12946483324847968\n",
      "Epoch 369/1000, Validation Loss: 0.14559148624539375\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 370/1000, Training Loss: 0.11792541027113888\n",
      "Epoch 370/1000, Validation Loss: 0.14554078318178654\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 371/1000, Training Loss: 0.11706105765758888\n",
      "Epoch 371/1000, Validation Loss: 0.14677377492189408\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 372/1000, Training Loss: 0.1251697520561078\n",
      "Epoch 372/1000, Validation Loss: 0.14480168074369432\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 373/1000, Training Loss: 0.1182372161142577\n",
      "Epoch 373/1000, Validation Loss: 0.14452690593898296\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 374/1000, Training Loss: 0.12106519236284144\n",
      "Epoch 374/1000, Validation Loss: 0.14457651413977146\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 375/1000, Training Loss: 0.11790288407720771\n",
      "Epoch 375/1000, Validation Loss: 0.14665181264281274\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 376/1000, Training Loss: 0.11673400003243924\n",
      "Epoch 376/1000, Validation Loss: 0.1448684439063072\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 377/1000, Training Loss: 0.11685144415526998\n",
      "Epoch 377/1000, Validation Loss: 0.14469826817512513\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 378/1000, Training Loss: 0.11652125265704942\n",
      "Epoch 378/1000, Validation Loss: 0.14597904048860072\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 379/1000, Training Loss: 0.11659518880518518\n",
      "Epoch 379/1000, Validation Loss: 0.14541560411453247\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 380/1000, Training Loss: 0.11780926263799854\n",
      "Epoch 380/1000, Validation Loss: 0.14456464424729348\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 381/1000, Training Loss: 0.34977983895177933\n",
      "Epoch 381/1000, Validation Loss: 0.14508377835154534\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 382/1000, Training Loss: 0.1306851233775709\n",
      "Epoch 382/1000, Validation Loss: 0.15088440403342246\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 383/1000, Training Loss: 0.11835272090199093\n",
      "Epoch 383/1000, Validation Loss: 0.14685968197882177\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 384/1000, Training Loss: 0.11574511096314025\n",
      "Epoch 384/1000, Validation Loss: 0.14524933695793152\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 385/1000, Training Loss: 0.11665830315620292\n",
      "Epoch 385/1000, Validation Loss: 0.1482401728630066\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 386/1000, Training Loss: 0.11622348128973196\n",
      "Epoch 386/1000, Validation Loss: 0.14406458660960197\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 387/1000, Training Loss: 0.11523310342283152\n",
      "Epoch 387/1000, Validation Loss: 0.14434337206184863\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 388/1000, Training Loss: 0.11549528666278895\n",
      "Epoch 388/1000, Validation Loss: 0.14449285268783568\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 389/1000, Training Loss: 0.11454191168184694\n",
      "Epoch 389/1000, Validation Loss: 0.14994002729654313\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 390/1000, Training Loss: 0.11511110084921158\n",
      "Epoch 390/1000, Validation Loss: 0.14428442865610122\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 391/1000, Training Loss: 0.11741636211381239\n",
      "Epoch 391/1000, Validation Loss: 0.14344246201217176\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 392/1000, Training Loss: 0.11537662594049584\n",
      "Epoch 392/1000, Validation Loss: 0.14459774419665336\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 393/1000, Training Loss: 0.11461521833039381\n",
      "Epoch 393/1000, Validation Loss: 0.14513144865632058\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 394/1000, Training Loss: 0.12329037713946081\n",
      "Epoch 394/1000, Validation Loss: 0.14799965023994446\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 395/1000, Training Loss: 0.1410959552900464\n",
      "Epoch 395/1000, Validation Loss: 0.14561519473791124\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 396/1000, Training Loss: 0.11426014781887252\n",
      "Epoch 396/1000, Validation Loss: 0.14519518613815308\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 397/1000, Training Loss: 0.11320104910172114\n",
      "Epoch 397/1000, Validation Loss: 0.14643570855259896\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 398/1000, Training Loss: 0.11417041600261833\n",
      "Epoch 398/1000, Validation Loss: 0.14498348757624627\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 399/1000, Training Loss: 0.11367114618712837\n",
      "Epoch 399/1000, Validation Loss: 0.14573334380984307\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 400/1000, Training Loss: 0.11322867247865503\n",
      "Epoch 400/1000, Validation Loss: 0.14516347050666809\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 401/1000, Training Loss: 0.11532456508161974\n",
      "Epoch 401/1000, Validation Loss: 0.14534835442900657\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 402/1000, Training Loss: 0.11317983687873565\n",
      "Epoch 402/1000, Validation Loss: 0.14503739029169083\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 403/1000, Training Loss: 0.11318065394388054\n",
      "Epoch 403/1000, Validation Loss: 0.14678442403674125\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 404/1000, Training Loss: 0.12374067335736517\n",
      "Epoch 404/1000, Validation Loss: 0.14553550779819488\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 405/1000, Training Loss: 0.12229797872258168\n",
      "Epoch 405/1000, Validation Loss: 0.14476651474833488\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 406/1000, Training Loss: 0.11427637569620713\n",
      "Epoch 406/1000, Validation Loss: 0.14655073434114457\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 407/1000, Training Loss: 0.11311810554858918\n",
      "Epoch 407/1000, Validation Loss: 0.14341541938483715\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 408/1000, Training Loss: 0.11278805156189264\n",
      "Epoch 408/1000, Validation Loss: 0.1437714844942093\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 409/1000, Training Loss: 0.11280522303765311\n",
      "Epoch 409/1000, Validation Loss: 0.1446225881576538\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 410/1000, Training Loss: 0.11240534907076782\n",
      "Epoch 410/1000, Validation Loss: 0.14426084719598292\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 411/1000, Training Loss: 0.11789872840631242\n",
      "Epoch 411/1000, Validation Loss: 0.1462877407670021\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 412/1000, Training Loss: 0.12372630681185161\n",
      "Epoch 412/1000, Validation Loss: 0.14457648657262326\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 413/1000, Training Loss: 0.13045836524928317\n",
      "Epoch 413/1000, Validation Loss: 0.15866219252347946\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 414/1000, Training Loss: 0.1352948322987775\n",
      "Epoch 414/1000, Validation Loss: 0.1465706057846546\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 415/1000, Training Loss: 0.11351801799701564\n",
      "Epoch 415/1000, Validation Loss: 0.14473674595355987\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 416/1000, Training Loss: 0.1122770451892589\n",
      "Epoch 416/1000, Validation Loss: 0.14438574351370334\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 417/1000, Training Loss: 0.11268895124949803\n",
      "Epoch 417/1000, Validation Loss: 0.14425638355314732\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 418/1000, Training Loss: 0.1303378705154447\n",
      "Epoch 418/1000, Validation Loss: 0.14438443556427955\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 419/1000, Training Loss: 0.12035876030463175\n",
      "Epoch 419/1000, Validation Loss: 0.14588664770126342\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 420/1000, Training Loss: 0.11351961814159271\n",
      "Epoch 420/1000, Validation Loss: 0.14507560171186923\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 421/1000, Training Loss: 0.12907368572903613\n",
      "Epoch 421/1000, Validation Loss: 0.1451111078262329\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 422/1000, Training Loss: 0.11770891535150654\n",
      "Epoch 422/1000, Validation Loss: 0.15113586261868478\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 423/1000, Training Loss: 0.12621189485870155\n",
      "Epoch 423/1000, Validation Loss: 0.14915081933140756\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 424/1000, Training Loss: 0.12330015679032716\n",
      "Epoch 424/1000, Validation Loss: 0.14774082750082015\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 425/1000, Training Loss: 0.11257317933874826\n",
      "Epoch 425/1000, Validation Loss: 0.1452150210738182\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 426/1000, Training Loss: 0.11185896688816623\n",
      "Epoch 426/1000, Validation Loss: 0.14393720403313637\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 427/1000, Training Loss: 0.11142817352518643\n",
      "Epoch 427/1000, Validation Loss: 0.14458250738680362\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 428/1000, Training Loss: 0.11212132548383784\n",
      "Epoch 428/1000, Validation Loss: 0.14392637126147748\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 429/1000, Training Loss: 0.1126314187605007\n",
      "Epoch 429/1000, Validation Loss: 0.14363476857542992\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 430/1000, Training Loss: 0.11573026037099314\n",
      "Epoch 430/1000, Validation Loss: 0.15172124281525612\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 431/1000, Training Loss: 0.1157440963406949\n",
      "Epoch 431/1000, Validation Loss: 0.14349062219262124\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 432/1000, Training Loss: 0.11543647324045499\n",
      "Epoch 432/1000, Validation Loss: 0.14361764043569564\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 433/1000, Training Loss: 0.11392178041312624\n",
      "Epoch 433/1000, Validation Loss: 0.14346572160720825\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 434/1000, Training Loss: 0.11145785780044047\n",
      "Epoch 434/1000, Validation Loss: 0.14413262903690338\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 435/1000, Training Loss: 0.11071306148397864\n",
      "Epoch 435/1000, Validation Loss: 0.14414691179990768\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 436/1000, Training Loss: 0.11066440690089703\n",
      "Epoch 436/1000, Validation Loss: 0.14444964826107026\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 437/1000, Training Loss: 0.1104016103846316\n",
      "Epoch 437/1000, Validation Loss: 0.1435938898473978\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 438/1000, Training Loss: 0.11418286645237137\n",
      "Epoch 438/1000, Validation Loss: 0.1460774466395378\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 439/1000, Training Loss: 0.11154822998123207\n",
      "Epoch 439/1000, Validation Loss: 0.14346221275627613\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 440/1000, Training Loss: 0.11047262858654208\n",
      "Epoch 440/1000, Validation Loss: 0.14331739358603954\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 441/1000, Training Loss: 0.11082376064915284\n",
      "Epoch 441/1000, Validation Loss: 0.1442828495055437\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 442/1000, Training Loss: 0.11247071463103388\n",
      "Epoch 442/1000, Validation Loss: 0.14398002848029137\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 443/1000, Training Loss: 0.1109378801511998\n",
      "Epoch 443/1000, Validation Loss: 0.14357937574386598\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 444/1000, Training Loss: 0.11783389206610474\n",
      "Epoch 444/1000, Validation Loss: 0.1468611963093281\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 445/1000, Training Loss: 0.11124730138516159\n",
      "Epoch 445/1000, Validation Loss: 0.1438317947089672\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 446/1000, Training Loss: 0.109290632160207\n",
      "Epoch 446/1000, Validation Loss: 0.14328425899147987\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 447/1000, Training Loss: 0.11180403828620966\n",
      "Epoch 447/1000, Validation Loss: 0.14490994960069656\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 448/1000, Training Loss: 0.1106513270539889\n",
      "Epoch 448/1000, Validation Loss: 0.14493408426642418\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 449/1000, Training Loss: 0.109595127595479\n",
      "Epoch 449/1000, Validation Loss: 0.14342138282954692\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 450/1000, Training Loss: 0.10944478493932847\n",
      "Epoch 450/1000, Validation Loss: 0.14386213421821595\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 451/1000, Training Loss: 0.10926783996789406\n",
      "Epoch 451/1000, Validation Loss: 0.1434393733739853\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 452/1000, Training Loss: 0.10925073576700194\n",
      "Epoch 452/1000, Validation Loss: 0.14280658289790155\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 453/1000, Training Loss: 0.1100085956459938\n",
      "Epoch 453/1000, Validation Loss: 0.14904219508171082\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 454/1000, Training Loss: 0.11065955255545822\n",
      "Epoch 454/1000, Validation Loss: 0.14277229383587836\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 455/1000, Training Loss: 0.11087515800460881\n",
      "Epoch 455/1000, Validation Loss: 0.14243808053433896\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 456/1000, Training Loss: 0.1095294713216158\n",
      "Epoch 456/1000, Validation Loss: 0.1426184244453907\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 457/1000, Training Loss: 0.10995000031064539\n",
      "Epoch 457/1000, Validation Loss: 0.1420602396130562\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 458/1000, Training Loss: 0.10943694435884348\n",
      "Epoch 458/1000, Validation Loss: 0.14335231408476828\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 459/1000, Training Loss: 0.16590226003352335\n",
      "Epoch 459/1000, Validation Loss: 0.14374429732561111\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 460/1000, Training Loss: 0.11642284935805947\n",
      "Epoch 460/1000, Validation Loss: 0.15759562253952025\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 461/1000, Training Loss: 0.11093263334466838\n",
      "Epoch 461/1000, Validation Loss: 0.1475447729229927\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 462/1000, Training Loss: 0.11050914417879254\n",
      "Epoch 462/1000, Validation Loss: 0.14507474340498447\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 463/1000, Training Loss: 0.11000606432956855\n",
      "Epoch 463/1000, Validation Loss: 0.14483477994799615\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 464/1000, Training Loss: 0.10869608705722973\n",
      "Epoch 464/1000, Validation Loss: 0.1452341742813587\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 465/1000, Training Loss: 0.1101347831096135\n",
      "Epoch 465/1000, Validation Loss: 0.14629218354821205\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 466/1000, Training Loss: 0.11177104455533017\n",
      "Epoch 466/1000, Validation Loss: 0.14609031304717063\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 467/1000, Training Loss: 0.10781061094491509\n",
      "Epoch 467/1000, Validation Loss: 0.14281233325600623\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 468/1000, Training Loss: 0.10772533659074529\n",
      "Epoch 468/1000, Validation Loss: 0.1453742753714323\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 469/1000, Training Loss: 0.10837590894958589\n",
      "Epoch 469/1000, Validation Loss: 0.14282807409763337\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 470/1000, Training Loss: 0.10788091652862289\n",
      "Epoch 470/1000, Validation Loss: 0.1432640627026558\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 471/1000, Training Loss: 0.10797065350357339\n",
      "Epoch 471/1000, Validation Loss: 0.14309524819254876\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 472/1000, Training Loss: 0.10857371223449032\n",
      "Epoch 472/1000, Validation Loss: 0.14283758848905564\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 473/1000, Training Loss: 0.10818588461923212\n",
      "Epoch 473/1000, Validation Loss: 0.1426183484494686\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 474/1000, Training Loss: 0.11844346723427959\n",
      "Epoch 474/1000, Validation Loss: 0.1505032479763031\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 475/1000, Training Loss: 0.12893467193184643\n",
      "Epoch 475/1000, Validation Loss: 0.14762305691838265\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 476/1000, Training Loss: 0.10961176009853564\n",
      "Epoch 476/1000, Validation Loss: 0.14191698059439659\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 477/1000, Training Loss: 0.10897800688832707\n",
      "Epoch 477/1000, Validation Loss: 0.1447359785437584\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 478/1000, Training Loss: 0.10736975586498339\n",
      "Epoch 478/1000, Validation Loss: 0.14140993915498257\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 479/1000, Training Loss: 0.10795585234083381\n",
      "Epoch 479/1000, Validation Loss: 0.14217476770281792\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 480/1000, Training Loss: 0.10674314011874445\n",
      "Epoch 480/1000, Validation Loss: 0.14186895750463008\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 481/1000, Training Loss: 0.10701603953744851\n",
      "Epoch 481/1000, Validation Loss: 0.14340085424482824\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 482/1000, Training Loss: 0.10767989875931366\n",
      "Epoch 482/1000, Validation Loss: 0.14261390045285224\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 483/1000, Training Loss: 0.1145804246120593\n",
      "Epoch 483/1000, Validation Loss: 0.1416889823973179\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 484/1000, Training Loss: 0.11174866830526084\n",
      "Epoch 484/1000, Validation Loss: 0.14238690435886384\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 485/1000, Training Loss: 0.10957768384148092\n",
      "Epoch 485/1000, Validation Loss: 0.1440737098455429\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 486/1000, Training Loss: 0.10821587462252115\n",
      "Epoch 486/1000, Validation Loss: 0.14669466614723206\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 487/1000, Training Loss: 0.10737943721999851\n",
      "Epoch 487/1000, Validation Loss: 0.14350733123719692\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 488/1000, Training Loss: 0.10634414892874523\n",
      "Epoch 488/1000, Validation Loss: 0.1453406222164631\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 489/1000, Training Loss: 0.10697681124449945\n",
      "Epoch 489/1000, Validation Loss: 0.14396349415183068\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 490/1000, Training Loss: 0.10659821152084452\n",
      "Epoch 490/1000, Validation Loss: 0.1434668056666851\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 491/1000, Training Loss: 0.10676985691094945\n",
      "Epoch 491/1000, Validation Loss: 0.14210978336632252\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 492/1000, Training Loss: 0.10702685501532602\n",
      "Epoch 492/1000, Validation Loss: 0.142780202627182\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 493/1000, Training Loss: 0.10663735983418511\n",
      "Epoch 493/1000, Validation Loss: 0.14709740728139878\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 494/1000, Training Loss: 0.13122562224081918\n",
      "Epoch 494/1000, Validation Loss: 0.14339544773101806\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 495/1000, Training Loss: 0.11094162836853488\n",
      "Epoch 495/1000, Validation Loss: 0.1418507769703865\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 496/1000, Training Loss: 0.10763726996568342\n",
      "Epoch 496/1000, Validation Loss: 0.14315174147486687\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 497/1000, Training Loss: 0.10850082469337127\n",
      "Epoch 497/1000, Validation Loss: 0.144944279640913\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 498/1000, Training Loss: 0.10732809695250847\n",
      "Epoch 498/1000, Validation Loss: 0.14119700603187085\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 499/1000, Training Loss: 0.1069314988220442\n",
      "Epoch 499/1000, Validation Loss: 0.14209257774055004\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 500/1000, Training Loss: 0.11397853537517436\n",
      "Epoch 500/1000, Validation Loss: 0.14842945635318755\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 501/1000, Training Loss: 0.1272787840342989\n",
      "Epoch 501/1000, Validation Loss: 0.14211266078054904\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 502/1000, Training Loss: 0.11880721626620666\n",
      "Epoch 502/1000, Validation Loss: 0.15764690488576888\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 503/1000, Training Loss: 0.11230431869626045\n",
      "Epoch 503/1000, Validation Loss: 0.14764201939105986\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 504/1000, Training Loss: 0.10612663619366347\n",
      "Epoch 504/1000, Validation Loss: 0.14225814417004584\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 505/1000, Training Loss: 0.10996464384244937\n",
      "Epoch 505/1000, Validation Loss: 0.1421866938471794\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 506/1000, Training Loss: 0.10671545955918584\n",
      "Epoch 506/1000, Validation Loss: 0.14159466251730918\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 507/1000, Training Loss: 0.10468553973124455\n",
      "Epoch 507/1000, Validation Loss: 0.14239371232688428\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 508/1000, Training Loss: 0.10505656580461814\n",
      "Epoch 508/1000, Validation Loss: 0.14488003998994828\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 509/1000, Training Loss: 0.10553107590599478\n",
      "Epoch 509/1000, Validation Loss: 0.1422581396996975\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 510/1000, Training Loss: 0.11533856260425904\n",
      "Epoch 510/1000, Validation Loss: 0.14334054328501225\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 511/1000, Training Loss: 0.11015755270936471\n",
      "Epoch 511/1000, Validation Loss: 0.1421573780477047\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 512/1000, Training Loss: 0.10563814673828435\n",
      "Epoch 512/1000, Validation Loss: 0.14165588207542895\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 513/1000, Training Loss: 0.10455930008163919\n",
      "Epoch 513/1000, Validation Loss: 0.1419951431453228\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 514/1000, Training Loss: 0.11028700299999293\n",
      "Epoch 514/1000, Validation Loss: 0.14077479913830757\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 515/1000, Training Loss: 0.10565624145105997\n",
      "Epoch 515/1000, Validation Loss: 0.14267604276537896\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 516/1000, Training Loss: 0.10472198535103862\n",
      "Epoch 516/1000, Validation Loss: 0.14168126359581948\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 517/1000, Training Loss: 0.10515780457667549\n",
      "Epoch 517/1000, Validation Loss: 0.1410996552556753\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 518/1000, Training Loss: 0.10968993209740695\n",
      "Epoch 518/1000, Validation Loss: 0.14344982989132404\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 519/1000, Training Loss: 0.10979960566642237\n",
      "Epoch 519/1000, Validation Loss: 0.14259119629859923\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 520/1000, Training Loss: 0.1047098145765818\n",
      "Epoch 520/1000, Validation Loss: 0.14309397339820862\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 521/1000, Training Loss: 0.10375448597558573\n",
      "Epoch 521/1000, Validation Loss: 0.1415909096598625\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 522/1000, Training Loss: 0.10420786606496846\n",
      "Epoch 522/1000, Validation Loss: 0.1439656749367714\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 523/1000, Training Loss: 0.10398107303954734\n",
      "Epoch 523/1000, Validation Loss: 0.14229094609618187\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 524/1000, Training Loss: 0.10401621434093435\n",
      "Epoch 524/1000, Validation Loss: 0.14267909079790114\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 525/1000, Training Loss: 0.10697186592162825\n",
      "Epoch 525/1000, Validation Loss: 0.1499569334089756\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 526/1000, Training Loss: 0.10743058393289211\n",
      "Epoch 526/1000, Validation Loss: 0.14123636148869992\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 527/1000, Training Loss: 0.10473883562817005\n",
      "Epoch 527/1000, Validation Loss: 0.13988292254507542\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 528/1000, Training Loss: 0.10363231092581854\n",
      "Epoch 528/1000, Validation Loss: 0.13988388255238532\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 529/1000, Training Loss: 0.1043488655750658\n",
      "Epoch 529/1000, Validation Loss: 0.14146556332707405\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 530/1000, Training Loss: 0.10330655655878432\n",
      "Epoch 530/1000, Validation Loss: 0.14185349270701408\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 531/1000, Training Loss: 0.1034142071673391\n",
      "Epoch 531/1000, Validation Loss: 0.13956162445247172\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 532/1000, Training Loss: 0.10273801827319332\n",
      "Epoch 532/1000, Validation Loss: 0.1451000303030014\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 533/1000, Training Loss: 0.10546542974371537\n",
      "Epoch 533/1000, Validation Loss: 0.14117016457021236\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 534/1000, Training Loss: 0.10599486135384616\n",
      "Epoch 534/1000, Validation Loss: 0.13946639448404313\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 535/1000, Training Loss: 0.1031169251484035\n",
      "Epoch 535/1000, Validation Loss: 0.27377384155988693\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 536/1000, Training Loss: 0.10393662810983027\n",
      "Epoch 536/1000, Validation Loss: 0.1397792797535658\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 537/1000, Training Loss: 0.10297103993156377\n",
      "Epoch 537/1000, Validation Loss: 0.14233403354883195\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 538/1000, Training Loss: 0.10280813883040466\n",
      "Epoch 538/1000, Validation Loss: 0.1401328392326832\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 539/1000, Training Loss: 0.10261663721472637\n",
      "Epoch 539/1000, Validation Loss: 0.14058093167841434\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 540/1000, Training Loss: 0.10237736225712868\n",
      "Epoch 540/1000, Validation Loss: 0.14075193963944913\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 541/1000, Training Loss: 0.10657255504937733\n",
      "Epoch 541/1000, Validation Loss: 0.140646530687809\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 542/1000, Training Loss: 0.10446072859214829\n",
      "Epoch 542/1000, Validation Loss: 0.1395262736827135\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 543/1000, Training Loss: 0.10413706229597915\n",
      "Epoch 543/1000, Validation Loss: 0.272360685095191\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 544/1000, Training Loss: 0.10334791966220912\n",
      "Epoch 544/1000, Validation Loss: 0.27090677730739116\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 545/1000, Training Loss: 0.10159178706132532\n",
      "Epoch 545/1000, Validation Loss: 0.13986793756484986\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 546/1000, Training Loss: 0.10197573750908714\n",
      "Epoch 546/1000, Validation Loss: 0.13994427248835564\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 547/1000, Training Loss: 0.10274716835542053\n",
      "Epoch 547/1000, Validation Loss: 0.14063984304666519\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 548/1000, Training Loss: 0.10465988458371629\n",
      "Epoch 548/1000, Validation Loss: 0.1397511787712574\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 549/1000, Training Loss: 0.10507916674867053\n",
      "Epoch 549/1000, Validation Loss: 0.14079269655048848\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 550/1000, Training Loss: 0.10486408403398943\n",
      "Epoch 550/1000, Validation Loss: 0.14008981138467788\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 551/1000, Training Loss: 0.1064903717853275\n",
      "Epoch 551/1000, Validation Loss: 0.277465020865202\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 552/1000, Training Loss: 0.10328929966279132\n",
      "Epoch 552/1000, Validation Loss: 0.1396002486348152\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 553/1000, Training Loss: 0.10764612388961456\n",
      "Epoch 553/1000, Validation Loss: 0.14029757678508759\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 554/1000, Training Loss: 0.111301905603386\n",
      "Epoch 554/1000, Validation Loss: 0.14176132790744306\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 555/1000, Training Loss: 0.11765713478420295\n",
      "Epoch 555/1000, Validation Loss: 0.14393012076616288\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 556/1000, Training Loss: 0.1091707307108057\n",
      "Epoch 556/1000, Validation Loss: 0.14137215837836264\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 557/1000, Training Loss: 0.10186539473487216\n",
      "Epoch 557/1000, Validation Loss: 0.1391107190400362\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 558/1000, Training Loss: 0.10061570227730508\n",
      "Epoch 558/1000, Validation Loss: 0.1391986645758152\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 559/1000, Training Loss: 0.11166178146559819\n",
      "Epoch 559/1000, Validation Loss: 0.13962919674813748\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 560/1000, Training Loss: 0.10924989131151461\n",
      "Epoch 560/1000, Validation Loss: 0.13956628143787383\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 561/1000, Training Loss: 0.11361519583300048\n",
      "Epoch 561/1000, Validation Loss: 0.14146494939923288\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 562/1000, Training Loss: 0.10555768915226366\n",
      "Epoch 562/1000, Validation Loss: 0.13714743889868258\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 563/1000, Training Loss: 0.11813651945661097\n",
      "Epoch 563/1000, Validation Loss: 0.13957105316221713\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 564/1000, Training Loss: 0.10646362858562283\n",
      "Epoch 564/1000, Validation Loss: 0.1415614750236273\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 565/1000, Training Loss: 0.10096942744637678\n",
      "Epoch 565/1000, Validation Loss: 0.13991087041795253\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 566/1000, Training Loss: 0.10019081889414543\n",
      "Epoch 566/1000, Validation Loss: 0.1401952937245369\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 567/1000, Training Loss: 0.10055253026532192\n",
      "Epoch 567/1000, Validation Loss: 0.2746156208217144\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 568/1000, Training Loss: 0.10000700751940438\n",
      "Epoch 568/1000, Validation Loss: 0.2766706317663193\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 569/1000, Training Loss: 0.12130329699492921\n",
      "Epoch 569/1000, Validation Loss: 0.14757957942783834\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 570/1000, Training Loss: 0.12785190606880895\n",
      "Epoch 570/1000, Validation Loss: 0.2749512538313866\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 571/1000, Training Loss: 0.10353309361665856\n",
      "Epoch 571/1000, Validation Loss: 0.2718396995216608\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 572/1000, Training Loss: 0.10113493453565181\n",
      "Epoch 572/1000, Validation Loss: 0.27167282029986384\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 573/1000, Training Loss: 0.100092376126311\n",
      "Epoch 573/1000, Validation Loss: 0.2708184503018856\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 574/1000, Training Loss: 0.09947634965618479\n",
      "Epoch 574/1000, Validation Loss: 0.27098447605967524\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 575/1000, Training Loss: 0.10142283945106993\n",
      "Epoch 575/1000, Validation Loss: 0.27048449255526064\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 576/1000, Training Loss: 0.10168467416114851\n",
      "Epoch 576/1000, Validation Loss: 0.13803316242992877\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 577/1000, Training Loss: 0.11235788230802499\n",
      "Epoch 577/1000, Validation Loss: 0.27458477169275286\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 578/1000, Training Loss: 0.10373202783022648\n",
      "Epoch 578/1000, Validation Loss: 0.27008624486625193\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 579/1000, Training Loss: 0.09984575051303003\n",
      "Epoch 579/1000, Validation Loss: 0.270456799864769\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 580/1000, Training Loss: 0.10556636604608274\n",
      "Epoch 580/1000, Validation Loss: 0.27455084323883056\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 581/1000, Training Loss: 0.10359703121232079\n",
      "Epoch 581/1000, Validation Loss: 0.13993383795022965\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 582/1000, Training Loss: 0.09884479875809656\n",
      "Epoch 582/1000, Validation Loss: 0.13967490270733834\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 583/1000, Training Loss: 0.09957603405357576\n",
      "Epoch 583/1000, Validation Loss: 0.13905901089310646\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 584/1000, Training Loss: 0.09872411739300391\n",
      "Epoch 584/1000, Validation Loss: 0.272707910835743\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 585/1000, Training Loss: 0.10275739519035115\n",
      "Epoch 585/1000, Validation Loss: 0.27368455976247785\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 586/1000, Training Loss: 0.10014133087094582\n",
      "Epoch 586/1000, Validation Loss: 0.13902691565454006\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 587/1000, Training Loss: 0.0987655380192925\n",
      "Epoch 587/1000, Validation Loss: 0.2703642681241035\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 588/1000, Training Loss: 0.11849188161831276\n",
      "Epoch 588/1000, Validation Loss: 0.2770322598516941\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 589/1000, Training Loss: 0.11582792427290377\n",
      "Epoch 589/1000, Validation Loss: 0.27526248916983603\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 590/1000, Training Loss: 0.10029569480056884\n",
      "Epoch 590/1000, Validation Loss: 0.2705654039978981\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 591/1000, Training Loss: 0.1007446973566331\n",
      "Epoch 591/1000, Validation Loss: 0.2711953066289425\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 592/1000, Training Loss: 0.10376472091850113\n",
      "Epoch 592/1000, Validation Loss: 0.2693678982555866\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 593/1000, Training Loss: 0.11204381477014691\n",
      "Epoch 593/1000, Validation Loss: 0.27395012490451337\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 594/1000, Training Loss: 0.10287287743937899\n",
      "Epoch 594/1000, Validation Loss: 0.2727746028453112\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 595/1000, Training Loss: 0.09859949837018754\n",
      "Epoch 595/1000, Validation Loss: 0.2710615564137697\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 596/1000, Training Loss: 0.09942228610937794\n",
      "Epoch 596/1000, Validation Loss: 0.26950455345213414\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 597/1000, Training Loss: 0.09795139078140687\n",
      "Epoch 597/1000, Validation Loss: 0.2691444132477045\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 598/1000, Training Loss: 0.10255694929875579\n",
      "Epoch 598/1000, Validation Loss: 0.13867430463433267\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 599/1000, Training Loss: 0.0989555446739199\n",
      "Epoch 599/1000, Validation Loss: 0.2689583271741867\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 600/1000, Training Loss: 0.09867730298463147\n",
      "Epoch 600/1000, Validation Loss: 0.2687946427613497\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 601/1000, Training Loss: 0.11822065725630405\n",
      "Epoch 601/1000, Validation Loss: 0.2885336332023144\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 602/1000, Training Loss: 0.14375328016923952\n",
      "Epoch 602/1000, Validation Loss: 0.13667244724929334\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 603/1000, Training Loss: 0.1025656375522707\n",
      "Epoch 603/1000, Validation Loss: 0.26709415949881077\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 604/1000, Training Loss: 0.09861267455191552\n",
      "Epoch 604/1000, Validation Loss: 0.2673641420900822\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 605/1000, Training Loss: 0.09769103216354315\n",
      "Epoch 605/1000, Validation Loss: 0.2675800949335098\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 606/1000, Training Loss: 0.0992639202113245\n",
      "Epoch 606/1000, Validation Loss: 0.2677920076996088\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 607/1000, Training Loss: 0.09869279106165849\n",
      "Epoch 607/1000, Validation Loss: 0.2676810994744301\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 608/1000, Training Loss: 0.09807693874280826\n",
      "Epoch 608/1000, Validation Loss: 0.26973938681185244\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 609/1000, Training Loss: 0.09815439717917174\n",
      "Epoch 609/1000, Validation Loss: 0.26929046735167506\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 610/1000, Training Loss: 0.09731834005637496\n",
      "Epoch 610/1000, Validation Loss: 0.270041024312377\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 611/1000, Training Loss: 0.09848040570139739\n",
      "Epoch 611/1000, Validation Loss: 0.2676050800830126\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 612/1000, Training Loss: 0.10045995263784539\n",
      "Epoch 612/1000, Validation Loss: 0.2676563959568739\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 613/1000, Training Loss: 0.09992122361619127\n",
      "Epoch 613/1000, Validation Loss: 0.26848495826125146\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 614/1000, Training Loss: 0.09741212451355714\n",
      "Epoch 614/1000, Validation Loss: 0.267518699914217\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 615/1000, Training Loss: 0.09722471317532128\n",
      "Epoch 615/1000, Validation Loss: 0.26851048655807974\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 616/1000, Training Loss: 0.09806487070140997\n",
      "Epoch 616/1000, Validation Loss: 0.13814383260905744\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 617/1000, Training Loss: 0.0978900896860104\n",
      "Epoch 617/1000, Validation Loss: 0.2680034637451172\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 618/1000, Training Loss: 0.09675333437089827\n",
      "Epoch 618/1000, Validation Loss: 0.2674607545137405\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 619/1000, Training Loss: 0.09759860142481093\n",
      "Epoch 619/1000, Validation Loss: 0.2684028759598732\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 620/1000, Training Loss: 0.09776051587187777\n",
      "Epoch 620/1000, Validation Loss: 0.2675409749150276\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 621/1000, Training Loss: 0.10102723400090255\n",
      "Epoch 621/1000, Validation Loss: 0.26728232353925707\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 622/1000, Training Loss: 0.10345703294025917\n",
      "Epoch 622/1000, Validation Loss: 0.26933994218707086\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 623/1000, Training Loss: 0.10285283471731578\n",
      "Epoch 623/1000, Validation Loss: 0.2729378901422024\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 624/1000, Training Loss: 0.10200231916764203\n",
      "Epoch 624/1000, Validation Loss: 0.270260901004076\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 625/1000, Training Loss: 0.09994110952624503\n",
      "Epoch 625/1000, Validation Loss: 0.27301590889692307\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 626/1000, Training Loss: 0.09652561124922239\n",
      "Epoch 626/1000, Validation Loss: 0.2690336093306541\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 627/1000, Training Loss: 0.09690891472878409\n",
      "Epoch 627/1000, Validation Loss: 0.2700446963310242\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 628/1000, Training Loss: 0.09672739652588143\n",
      "Epoch 628/1000, Validation Loss: 0.2683821082115173\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 629/1000, Training Loss: 0.09945452428769831\n",
      "Epoch 629/1000, Validation Loss: 0.2677891667932272\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 630/1000, Training Loss: 0.09683861613145792\n",
      "Epoch 630/1000, Validation Loss: 0.13834373019635676\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 631/1000, Training Loss: 0.0976189464834569\n",
      "Epoch 631/1000, Validation Loss: 0.2695096217095852\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 632/1000, Training Loss: 0.10002815708810207\n",
      "Epoch 632/1000, Validation Loss: 0.14050761461257935\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 633/1000, Training Loss: 0.34471737261058066\n",
      "Epoch 633/1000, Validation Loss: 0.26998321563005445\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 634/1000, Training Loss: 0.1139425781975482\n",
      "Epoch 634/1000, Validation Loss: 0.1479490265250206\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 635/1000, Training Loss: 0.10066755999831038\n",
      "Epoch 635/1000, Validation Loss: 0.14431507028639318\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 636/1000, Training Loss: 0.0975822390264868\n",
      "Epoch 636/1000, Validation Loss: 0.1409677669405937\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 637/1000, Training Loss: 0.09693191244321711\n",
      "Epoch 637/1000, Validation Loss: 0.1407184075564146\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 638/1000, Training Loss: 0.11400048383602909\n",
      "Epoch 638/1000, Validation Loss: 0.14253510683774948\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 639/1000, Training Loss: 0.10879831082151856\n",
      "Epoch 639/1000, Validation Loss: 0.13935887217521667\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 640/1000, Training Loss: 0.09648666304408335\n",
      "Epoch 640/1000, Validation Loss: 0.1381467215716839\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 641/1000, Training Loss: 0.09732202119102665\n",
      "Epoch 641/1000, Validation Loss: 0.1378361616283655\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 642/1000, Training Loss: 0.09738452559081363\n",
      "Epoch 642/1000, Validation Loss: 0.13751698471605778\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 643/1000, Training Loss: 0.09618757917162306\n",
      "Epoch 643/1000, Validation Loss: 0.13714521788060666\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 644/1000, Training Loss: 0.09599504418725237\n",
      "Epoch 644/1000, Validation Loss: 0.13835939206182957\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 645/1000, Training Loss: 0.09601090597509171\n",
      "Epoch 645/1000, Validation Loss: 0.27010764703154566\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 646/1000, Training Loss: 0.0968228945252942\n",
      "Epoch 646/1000, Validation Loss: 0.270959559828043\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 647/1000, Training Loss: 0.09656888896636491\n",
      "Epoch 647/1000, Validation Loss: 0.13728726021945475\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 648/1000, Training Loss: 0.09579508552469276\n",
      "Epoch 648/1000, Validation Loss: 0.1383991703391075\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 649/1000, Training Loss: 0.27498040815778807\n",
      "Epoch 649/1000, Validation Loss: 0.13699671253561974\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 650/1000, Training Loss: 0.1188737571823853\n",
      "Epoch 650/1000, Validation Loss: 0.14886019863188266\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 651/1000, Training Loss: 0.09977953200056315\n",
      "Epoch 651/1000, Validation Loss: 0.14060240425169468\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 652/1000, Training Loss: 0.09691653700143683\n",
      "Epoch 652/1000, Validation Loss: 0.1394663669168949\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 653/1000, Training Loss: 0.10135961747636982\n",
      "Epoch 653/1000, Validation Loss: 0.1390361849218607\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 654/1000, Training Loss: 0.10013840528314605\n",
      "Epoch 654/1000, Validation Loss: 0.13741827011108398\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 655/1000, Training Loss: 0.10314840421664949\n",
      "Epoch 655/1000, Validation Loss: 0.1402734663337469\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 656/1000, Training Loss: 0.10119267706485913\n",
      "Epoch 656/1000, Validation Loss: 0.1385976482182741\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 657/1000, Training Loss: 0.09575623659703507\n",
      "Epoch 657/1000, Validation Loss: 0.1399458322674036\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 658/1000, Training Loss: 0.09688820153036538\n",
      "Epoch 658/1000, Validation Loss: 0.13828023038804532\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 659/1000, Training Loss: 0.09663924313031648\n",
      "Epoch 659/1000, Validation Loss: 0.13748670630156995\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 660/1000, Training Loss: 0.0977125105758508\n",
      "Epoch 660/1000, Validation Loss: 0.27391340062022207\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 661/1000, Training Loss: 0.09934898275955051\n",
      "Epoch 661/1000, Validation Loss: 0.1383744265884161\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 662/1000, Training Loss: 0.09710888547238473\n",
      "Epoch 662/1000, Validation Loss: 0.27047265209257604\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 663/1000, Training Loss: 0.0958760159875394\n",
      "Epoch 663/1000, Validation Loss: 0.1372165448963642\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 664/1000, Training Loss: 0.09534927727837189\n",
      "Epoch 664/1000, Validation Loss: 0.27084096483886244\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 665/1000, Training Loss: 0.10477940376628847\n",
      "Epoch 665/1000, Validation Loss: 0.1378983970731497\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 666/1000, Training Loss: 0.10565421624364806\n",
      "Epoch 666/1000, Validation Loss: 0.269966946169734\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 667/1000, Training Loss: 0.09889364410556999\n",
      "Epoch 667/1000, Validation Loss: 0.1391115415841341\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 668/1000, Training Loss: 0.09819412698932722\n",
      "Epoch 668/1000, Validation Loss: 0.13735493496060372\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 669/1000, Training Loss: 0.10105465995330437\n",
      "Epoch 669/1000, Validation Loss: 0.2741236947476864\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 670/1000, Training Loss: 0.1006026491522789\n",
      "Epoch 670/1000, Validation Loss: 0.1404528807848692\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 671/1000, Training Loss: 0.09643799329506139\n",
      "Epoch 671/1000, Validation Loss: 0.13871149346232414\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 672/1000, Training Loss: 0.0962053842696489\n",
      "Epoch 672/1000, Validation Loss: 0.2689899418503046\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 673/1000, Training Loss: 0.09760463792903751\n",
      "Epoch 673/1000, Validation Loss: 0.2679984327405691\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 674/1000, Training Loss: 0.09809150320349955\n",
      "Epoch 674/1000, Validation Loss: 0.27347595877945424\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 675/1000, Training Loss: 0.0970997918470233\n",
      "Epoch 675/1000, Validation Loss: 0.2688385471701622\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 676/1000, Training Loss: 0.09809878804520064\n",
      "Epoch 676/1000, Validation Loss: 0.2752178210765123\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 677/1000, Training Loss: 0.098376912594631\n",
      "Epoch 677/1000, Validation Loss: 0.2672112349420786\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 678/1000, Training Loss: 0.0950752313742535\n",
      "Epoch 678/1000, Validation Loss: 0.26892640963196757\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 679/1000, Training Loss: 0.09627398413574031\n",
      "Epoch 679/1000, Validation Loss: 0.26869578994810583\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 680/1000, Training Loss: 0.09557282861650866\n",
      "Epoch 680/1000, Validation Loss: 0.2697624143213034\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 681/1000, Training Loss: 0.094183923274863\n",
      "Epoch 681/1000, Validation Loss: 0.2679217286407948\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 682/1000, Training Loss: 0.10770427651118998\n",
      "Epoch 682/1000, Validation Loss: 0.2707447402179241\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 683/1000, Training Loss: 0.10445351314311045\n",
      "Epoch 683/1000, Validation Loss: 0.272984329611063\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 684/1000, Training Loss: 0.0951843683187935\n",
      "Epoch 684/1000, Validation Loss: 0.2689724303781986\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 685/1000, Training Loss: 0.11944582444780014\n",
      "Epoch 685/1000, Validation Loss: 0.27882532179355624\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 686/1000, Training Loss: 0.10840431622722904\n",
      "Epoch 686/1000, Validation Loss: 0.14044674560427667\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 687/1000, Training Loss: 0.09573508352589082\n",
      "Epoch 687/1000, Validation Loss: 0.2708161260932684\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 688/1000, Training Loss: 0.0953991012169104\n",
      "Epoch 688/1000, Validation Loss: 0.26945328190922735\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 689/1000, Training Loss: 0.09471174683787074\n",
      "Epoch 689/1000, Validation Loss: 0.2713549628853798\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 690/1000, Training Loss: 0.0949713406872059\n",
      "Epoch 690/1000, Validation Loss: 0.26912950426340104\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 691/1000, Training Loss: 0.09501884678008413\n",
      "Epoch 691/1000, Validation Loss: 0.26914782747626304\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 692/1000, Training Loss: 0.09429413328568141\n",
      "Epoch 692/1000, Validation Loss: 0.268552328273654\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 693/1000, Training Loss: 0.09406665588419534\n",
      "Epoch 693/1000, Validation Loss: 0.2688844077289104\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 694/1000, Training Loss: 0.0972181617775384\n",
      "Epoch 694/1000, Validation Loss: 0.2694221090525389\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 695/1000, Training Loss: 0.09412267455812909\n",
      "Epoch 695/1000, Validation Loss: 0.2686966545879841\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 696/1000, Training Loss: 0.09471501808102224\n",
      "Epoch 696/1000, Validation Loss: 0.26880610436201097\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 697/1000, Training Loss: 0.09378867114291471\n",
      "Epoch 697/1000, Validation Loss: 0.2680204246193171\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 698/1000, Training Loss: 0.09542998065258942\n",
      "Epoch 698/1000, Validation Loss: 0.26982875615358354\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 699/1000, Training Loss: 0.09825577638020702\n",
      "Epoch 699/1000, Validation Loss: 0.2706996642053127\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 700/1000, Training Loss: 0.09689878190265205\n",
      "Epoch 700/1000, Validation Loss: 0.2669734723865986\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 701/1000, Training Loss: 0.09445405649200314\n",
      "Epoch 701/1000, Validation Loss: 0.26699731796979903\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 702/1000, Training Loss: 0.10724100163754295\n",
      "Epoch 702/1000, Validation Loss: 0.26900675520300865\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 703/1000, Training Loss: 0.09847524254491516\n",
      "Epoch 703/1000, Validation Loss: 0.270052682980895\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 704/1000, Training Loss: 0.09452714646856547\n",
      "Epoch 704/1000, Validation Loss: 0.26708118468523023\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 705/1000, Training Loss: 0.09366366344472102\n",
      "Epoch 705/1000, Validation Loss: 0.27083723396062853\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 706/1000, Training Loss: 0.09826509756784813\n",
      "Epoch 706/1000, Validation Loss: 0.27340033911168576\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 707/1000, Training Loss: 0.09438481660304117\n",
      "Epoch 707/1000, Validation Loss: 0.26831984594464303\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 708/1000, Training Loss: 0.09423469474502638\n",
      "Epoch 708/1000, Validation Loss: 0.26855072267353536\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 709/1000, Training Loss: 0.09401500279850819\n",
      "Epoch 709/1000, Validation Loss: 0.2697077408432961\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 710/1000, Training Loss: 0.09432972552181751\n",
      "Epoch 710/1000, Validation Loss: 0.2677174545824528\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 711/1000, Training Loss: 0.09414608418649319\n",
      "Epoch 711/1000, Validation Loss: 0.2685311187058687\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 712/1000, Training Loss: 0.09502815072657683\n",
      "Epoch 712/1000, Validation Loss: 0.2700532853603363\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 713/1000, Training Loss: 0.09413834296020807\n",
      "Epoch 713/1000, Validation Loss: 0.2674462404102087\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 714/1000, Training Loss: 0.09404410294019709\n",
      "Epoch 714/1000, Validation Loss: 0.26890043430030347\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 715/1000, Training Loss: 0.09548997977638946\n",
      "Epoch 715/1000, Validation Loss: 0.27182746678590775\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 716/1000, Training Loss: 0.0960988522160287\n",
      "Epoch 716/1000, Validation Loss: 0.2684623282402754\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 717/1000, Training Loss: 0.09334408858215765\n",
      "Epoch 717/1000, Validation Loss: 0.2683655429631472\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 718/1000, Training Loss: 0.09343946927829701\n",
      "Epoch 718/1000, Validation Loss: 0.26828447729349136\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 719/1000, Training Loss: 0.09278604927627991\n",
      "Epoch 719/1000, Validation Loss: 0.26712754033505914\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 720/1000, Training Loss: 0.093353680548984\n",
      "Epoch 720/1000, Validation Loss: 0.2684352986514568\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 721/1000, Training Loss: 0.09327499798514376\n",
      "Epoch 721/1000, Validation Loss: 0.2666655495762825\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 722/1000, Training Loss: 0.09381065612861747\n",
      "Epoch 722/1000, Validation Loss: 0.26833105012774466\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 723/1000, Training Loss: 0.0933401830056335\n",
      "Epoch 723/1000, Validation Loss: 0.26734918132424357\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 724/1000, Training Loss: 0.09350760310303931\n",
      "Epoch 724/1000, Validation Loss: 0.2669086094945669\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 725/1000, Training Loss: 0.10152586973180958\n",
      "Epoch 725/1000, Validation Loss: 0.14718784615397454\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 726/1000, Training Loss: 0.11502752869730067\n",
      "Epoch 726/1000, Validation Loss: 0.2763503804802895\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 727/1000, Training Loss: 0.09364139863564827\n",
      "Epoch 727/1000, Validation Loss: 0.26908315531909466\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 728/1000, Training Loss: 0.09295733002929017\n",
      "Epoch 728/1000, Validation Loss: 0.26897345632314684\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 729/1000, Training Loss: 0.09926942261118515\n",
      "Epoch 729/1000, Validation Loss: 0.26735853813588617\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 730/1000, Training Loss: 0.09539593737595257\n",
      "Epoch 730/1000, Validation Loss: 0.26804270297288896\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 731/1000, Training Loss: 0.09268953396096156\n",
      "Epoch 731/1000, Validation Loss: 0.26705000177025795\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 732/1000, Training Loss: 0.09338738606767912\n",
      "Epoch 732/1000, Validation Loss: 0.2673763737082481\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 733/1000, Training Loss: 0.09394212483483202\n",
      "Epoch 733/1000, Validation Loss: 0.26707293801009657\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 734/1000, Training Loss: 0.09177201694133234\n",
      "Epoch 734/1000, Validation Loss: 0.2669656127691269\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 735/1000, Training Loss: 0.09255328321117251\n",
      "Epoch 735/1000, Validation Loss: 0.2678114537149668\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 736/1000, Training Loss: 0.09255306780630466\n",
      "Epoch 736/1000, Validation Loss: 0.2673698581755161\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 737/1000, Training Loss: 0.097201459255873\n",
      "Epoch 737/1000, Validation Loss: 0.2685234609991312\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 738/1000, Training Loss: 0.09560487952594664\n",
      "Epoch 738/1000, Validation Loss: 0.2672521471977234\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 739/1000, Training Loss: 0.09465398566395657\n",
      "Epoch 739/1000, Validation Loss: 0.26636093445122244\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 740/1000, Training Loss: 0.09244008471860606\n",
      "Epoch 740/1000, Validation Loss: 0.26685117930173874\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 741/1000, Training Loss: 0.09271483467526588\n",
      "Epoch 741/1000, Validation Loss: 0.2684771977365017\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 742/1000, Training Loss: 0.09584850620697527\n",
      "Epoch 742/1000, Validation Loss: 0.2671415664255619\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 743/1000, Training Loss: 0.09853192924649692\n",
      "Epoch 743/1000, Validation Loss: 0.2731979161500931\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 744/1000, Training Loss: 0.09460450840346954\n",
      "Epoch 744/1000, Validation Loss: 0.27089466974139215\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 745/1000, Training Loss: 0.0986444372318539\n",
      "Epoch 745/1000, Validation Loss: 0.27242203913629054\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 746/1000, Training Loss: 0.09764500564956595\n",
      "Epoch 746/1000, Validation Loss: 0.26851682253181935\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 747/1000, Training Loss: 0.0935366703494105\n",
      "Epoch 747/1000, Validation Loss: 0.26620555855333805\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 748/1000, Training Loss: 0.09220287919628854\n",
      "Epoch 748/1000, Validation Loss: 0.26705028861761093\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 749/1000, Training Loss: 0.09230310813178204\n",
      "Epoch 749/1000, Validation Loss: 0.26696232333779335\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 750/1000, Training Loss: 0.09209737495756645\n",
      "Epoch 750/1000, Validation Loss: 0.27051924243569375\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 751/1000, Training Loss: 0.09205693013819993\n",
      "Epoch 751/1000, Validation Loss: 0.26861391589045525\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 752/1000, Training Loss: 0.10156428046962794\n",
      "Epoch 752/1000, Validation Loss: 0.2706024952232838\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 753/1000, Training Loss: 0.10056611837125291\n",
      "Epoch 753/1000, Validation Loss: 0.27809818312525747\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 754/1000, Training Loss: 0.09315340403541576\n",
      "Epoch 754/1000, Validation Loss: 0.26554535552859304\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 755/1000, Training Loss: 0.09178087291967603\n",
      "Epoch 755/1000, Validation Loss: 0.2664231352508068\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 756/1000, Training Loss: 0.09191159268512446\n",
      "Epoch 756/1000, Validation Loss: 0.2663132783025503\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 757/1000, Training Loss: 0.11070828074041535\n",
      "Epoch 757/1000, Validation Loss: 0.26818197779357433\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 758/1000, Training Loss: 0.09610825803211615\n",
      "Epoch 758/1000, Validation Loss: 0.2668664462864399\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 759/1000, Training Loss: 0.09278720566162876\n",
      "Epoch 759/1000, Validation Loss: 0.267536311596632\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 760/1000, Training Loss: 0.09134749162430857\n",
      "Epoch 760/1000, Validation Loss: 0.2669865623116493\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 761/1000, Training Loss: 0.09235058151477692\n",
      "Epoch 761/1000, Validation Loss: 0.26650483421981336\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 762/1000, Training Loss: 0.09069030724612272\n",
      "Epoch 762/1000, Validation Loss: 0.2701310567557812\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 763/1000, Training Loss: 0.09108889190817945\n",
      "Epoch 763/1000, Validation Loss: 0.2665235687047243\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 764/1000, Training Loss: 0.0916237464749857\n",
      "Epoch 764/1000, Validation Loss: 0.27624701857566836\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 765/1000, Training Loss: 0.09264860108640849\n",
      "Epoch 765/1000, Validation Loss: 0.2678743481636047\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 766/1000, Training Loss: 0.09061943574616795\n",
      "Epoch 766/1000, Validation Loss: 0.2689159482717514\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 767/1000, Training Loss: 0.09112902745312336\n",
      "Epoch 767/1000, Validation Loss: 0.2668665420264006\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 768/1000, Training Loss: 0.09057138001833878\n",
      "Epoch 768/1000, Validation Loss: 0.2666239980608225\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 769/1000, Training Loss: 0.09365161672672805\n",
      "Epoch 769/1000, Validation Loss: 0.2720766879618168\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 770/1000, Training Loss: 0.09148092136499197\n",
      "Epoch 770/1000, Validation Loss: 0.26649641804397106\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 771/1000, Training Loss: 0.09108275418061655\n",
      "Epoch 771/1000, Validation Loss: 0.26831142976880074\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 772/1000, Training Loss: 0.09079152535574109\n",
      "Epoch 772/1000, Validation Loss: 0.2666072115302086\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 773/1000, Training Loss: 0.09036338658019054\n",
      "Epoch 773/1000, Validation Loss: 0.2693266648799181\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 774/1000, Training Loss: 0.09196985848978453\n",
      "Epoch 774/1000, Validation Loss: 0.26680822633206847\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 775/1000, Training Loss: 0.09191446593507077\n",
      "Epoch 775/1000, Validation Loss: 0.2682771645486355\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 776/1000, Training Loss: 0.10321183407715723\n",
      "Epoch 776/1000, Validation Loss: 0.2668489806354046\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 777/1000, Training Loss: 0.10410752585249058\n",
      "Epoch 777/1000, Validation Loss: 0.2660985827445984\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 778/1000, Training Loss: 0.11058370827459822\n",
      "Epoch 778/1000, Validation Loss: 0.27929921373724936\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 779/1000, Training Loss: 0.10349419287961734\n",
      "Epoch 779/1000, Validation Loss: 0.2659780077636242\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 780/1000, Training Loss: 0.0923805429655275\n",
      "Epoch 780/1000, Validation Loss: 0.26616247519850733\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 781/1000, Training Loss: 0.09080721353758218\n",
      "Epoch 781/1000, Validation Loss: 0.26662253886461257\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 782/1000, Training Loss: 0.12004666811987466\n",
      "Epoch 782/1000, Validation Loss: 0.2723892342299223\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 783/1000, Training Loss: 0.10111759968248069\n",
      "Epoch 783/1000, Validation Loss: 0.269997376203537\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 784/1000, Training Loss: 0.09181452812809571\n",
      "Epoch 784/1000, Validation Loss: 0.26993789747357366\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 785/1000, Training Loss: 0.09233945768837835\n",
      "Epoch 785/1000, Validation Loss: 0.2672005034983158\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 786/1000, Training Loss: 0.08986735490850829\n",
      "Epoch 786/1000, Validation Loss: 0.2674956411123276\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 787/1000, Training Loss: 0.09061757712533688\n",
      "Epoch 787/1000, Validation Loss: 0.26658373810350894\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 788/1000, Training Loss: 0.09077718590998195\n",
      "Epoch 788/1000, Validation Loss: 0.27005054205656054\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 789/1000, Training Loss: 0.09021924936449995\n",
      "Epoch 789/1000, Validation Loss: 0.26652689911425115\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 790/1000, Training Loss: 0.09042948348374635\n",
      "Epoch 790/1000, Validation Loss: 0.27244193479418755\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 791/1000, Training Loss: 0.09015091018769525\n",
      "Epoch 791/1000, Validation Loss: 0.26611019521951673\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 792/1000, Training Loss: 0.09008996926394192\n",
      "Epoch 792/1000, Validation Loss: 0.27138413712382314\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 793/1000, Training Loss: 0.09146044414543145\n",
      "Epoch 793/1000, Validation Loss: 0.2682918604463339\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 794/1000, Training Loss: 0.0898915061033507\n",
      "Epoch 794/1000, Validation Loss: 0.2664457708597183\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 795/1000, Training Loss: 0.09749593563816127\n",
      "Epoch 795/1000, Validation Loss: 0.2676932241767645\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 796/1000, Training Loss: 0.09972926407285473\n",
      "Epoch 796/1000, Validation Loss: 0.26760744862258434\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 797/1000, Training Loss: 0.10142383786539237\n",
      "Epoch 797/1000, Validation Loss: 0.2671896941959858\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 798/1000, Training Loss: 0.09190835719431223\n",
      "Epoch 798/1000, Validation Loss: 0.26717664673924446\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 799/1000, Training Loss: 0.09009859349530683\n",
      "Epoch 799/1000, Validation Loss: 0.2661017391830683\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 800/1000, Training Loss: 0.08968886393396293\n",
      "Epoch 800/1000, Validation Loss: 0.26696482934057714\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 801/1000, Training Loss: 0.0907355222449291\n",
      "Epoch 801/1000, Validation Loss: 0.2658781036734581\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 802/1000, Training Loss: 0.08991480063579782\n",
      "Epoch 802/1000, Validation Loss: 0.26594105586409567\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 803/1000, Training Loss: 0.08982305234188542\n",
      "Epoch 803/1000, Validation Loss: 0.26655017025768757\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 804/1000, Training Loss: 0.08917191007411947\n",
      "Epoch 804/1000, Validation Loss: 0.26603927947580813\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 805/1000, Training Loss: 0.10314825115104516\n",
      "Epoch 805/1000, Validation Loss: 0.2709114894270897\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 806/1000, Training Loss: 0.10323331291403841\n",
      "Epoch 806/1000, Validation Loss: 0.2657596156001091\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 807/1000, Training Loss: 0.10092025440113217\n",
      "Epoch 807/1000, Validation Loss: 0.26867393366992476\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 808/1000, Training Loss: 0.1015333417876094\n",
      "Epoch 808/1000, Validation Loss: 0.2677053291350603\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 809/1000, Training Loss: 0.09105725685074896\n",
      "Epoch 809/1000, Validation Loss: 0.2674685973674059\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 810/1000, Training Loss: 0.09754120857984412\n",
      "Epoch 810/1000, Validation Loss: 0.2737457748502493\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 811/1000, Training Loss: 0.10080638579001613\n",
      "Epoch 811/1000, Validation Loss: 0.26520544216036795\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 812/1000, Training Loss: 0.08997481188271195\n",
      "Epoch 812/1000, Validation Loss: 0.2657116647809744\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 813/1000, Training Loss: 0.08983851582104084\n",
      "Epoch 813/1000, Validation Loss: 0.26834944672882555\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 814/1000, Training Loss: 0.0888307280598811\n",
      "Epoch 814/1000, Validation Loss: 0.2680025339126587\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 815/1000, Training Loss: 0.08997888765075271\n",
      "Epoch 815/1000, Validation Loss: 0.2665827009826899\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 816/1000, Training Loss: 0.08929417907789934\n",
      "Epoch 816/1000, Validation Loss: 0.26988829858601093\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 817/1000, Training Loss: 0.09094824108715151\n",
      "Epoch 817/1000, Validation Loss: 0.26742876060307025\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 818/1000, Training Loss: 0.08996916964194195\n",
      "Epoch 818/1000, Validation Loss: 0.26669534146785734\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 819/1000, Training Loss: 0.09023711616064961\n",
      "Epoch 819/1000, Validation Loss: 0.265941496938467\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 820/1000, Training Loss: 0.09072479065142426\n",
      "Epoch 820/1000, Validation Loss: 0.2701523296535015\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 821/1000, Training Loss: 0.09014461369745544\n",
      "Epoch 821/1000, Validation Loss: 0.2707896839827299\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 822/1000, Training Loss: 0.09228345328101925\n",
      "Epoch 822/1000, Validation Loss: 0.2691282991319895\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 823/1000, Training Loss: 0.09441657538306625\n",
      "Epoch 823/1000, Validation Loss: 0.2661906287074089\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 824/1000, Training Loss: 0.09795376570785747\n",
      "Epoch 824/1000, Validation Loss: 0.26710230447351935\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 825/1000, Training Loss: 0.09384144674621377\n",
      "Epoch 825/1000, Validation Loss: 0.2671517670154572\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 826/1000, Training Loss: 0.09012349826457466\n",
      "Epoch 826/1000, Validation Loss: 0.2654582135379314\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 827/1000, Training Loss: 0.0887964456228028\n",
      "Epoch 827/1000, Validation Loss: 0.26601373702287673\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 828/1000, Training Loss: 0.08986048699886191\n",
      "Epoch 828/1000, Validation Loss: 0.2704687103629112\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 829/1000, Training Loss: 0.08993449894820943\n",
      "Epoch 829/1000, Validation Loss: 0.2704419005662203\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 830/1000, Training Loss: 0.08979679159246719\n",
      "Epoch 830/1000, Validation Loss: 0.26588676422834395\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 831/1000, Training Loss: 0.08791121872170204\n",
      "Epoch 831/1000, Validation Loss: 0.2665329407900572\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 832/1000, Training Loss: 0.08781020358369193\n",
      "Epoch 832/1000, Validation Loss: 0.26891802810132504\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 833/1000, Training Loss: 0.0885122444699795\n",
      "Epoch 833/1000, Validation Loss: 0.2668556936085224\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 834/1000, Training Loss: 0.08869186963192095\n",
      "Epoch 834/1000, Validation Loss: 0.2655353739857674\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 835/1000, Training Loss: 0.08903737132455788\n",
      "Epoch 835/1000, Validation Loss: 0.26621477827429774\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 836/1000, Training Loss: 0.08784057864663648\n",
      "Epoch 836/1000, Validation Loss: 0.2662798449397087\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 837/1000, Training Loss: 0.08786057798972573\n",
      "Epoch 837/1000, Validation Loss: 0.2656337182968855\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 838/1000, Training Loss: 0.0876068892140048\n",
      "Epoch 838/1000, Validation Loss: 0.26702148020267485\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 839/1000, Training Loss: 0.08878478355815306\n",
      "Epoch 839/1000, Validation Loss: 0.2677032247185707\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 840/1000, Training Loss: 0.08920503912254478\n",
      "Epoch 840/1000, Validation Loss: 0.26690519526600837\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 841/1000, Training Loss: 0.08848738758003039\n",
      "Epoch 841/1000, Validation Loss: 0.26666031815111635\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 842/1000, Training Loss: 0.0904546476462308\n",
      "Epoch 842/1000, Validation Loss: 0.2723363310098648\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 843/1000, Training Loss: 0.08890150867598862\n",
      "Epoch 843/1000, Validation Loss: 0.26511715464293956\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 844/1000, Training Loss: 0.08880979061245407\n",
      "Epoch 844/1000, Validation Loss: 0.26635837368667126\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 845/1000, Training Loss: 0.08811417254893218\n",
      "Epoch 845/1000, Validation Loss: 0.26820938624441626\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 846/1000, Training Loss: 0.08974487835246905\n",
      "Epoch 846/1000, Validation Loss: 0.2680064108222723\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 847/1000, Training Loss: 0.08826669535654433\n",
      "Epoch 847/1000, Validation Loss: 0.2706263538450003\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 848/1000, Training Loss: 0.08850284499717151\n",
      "Epoch 848/1000, Validation Loss: 0.26794062182307243\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 849/1000, Training Loss: 0.09083458207839844\n",
      "Epoch 849/1000, Validation Loss: 0.2662425857037306\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 850/1000, Training Loss: 0.09435961719353538\n",
      "Epoch 850/1000, Validation Loss: 0.26566051281988623\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 851/1000, Training Loss: 0.0890134109878184\n",
      "Epoch 851/1000, Validation Loss: 0.2667008925229311\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 852/1000, Training Loss: 0.08694961944768817\n",
      "Epoch 852/1000, Validation Loss: 0.2660599503666162\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 853/1000, Training Loss: 0.08975130944129299\n",
      "Epoch 853/1000, Validation Loss: 0.26922524310648444\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 854/1000, Training Loss: 0.09079095482022739\n",
      "Epoch 854/1000, Validation Loss: 0.2669585395604372\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 855/1000, Training Loss: 0.08797366964612577\n",
      "Epoch 855/1000, Validation Loss: 0.2670710749924183\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 856/1000, Training Loss: 0.08773531589437933\n",
      "Epoch 856/1000, Validation Loss: 0.26858536526560783\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 857/1000, Training Loss: 0.0880273110672658\n",
      "Epoch 857/1000, Validation Loss: 0.26625683829188346\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 858/1000, Training Loss: 0.0876017882263149\n",
      "Epoch 858/1000, Validation Loss: 0.26718683168292046\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 859/1000, Training Loss: 0.0877863964312436\n",
      "Epoch 859/1000, Validation Loss: 0.2669535592198372\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 860/1000, Training Loss: 0.0873444802055019\n",
      "Epoch 860/1000, Validation Loss: 0.2680951002985239\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 861/1000, Training Loss: 0.08743978693497616\n",
      "Epoch 861/1000, Validation Loss: 0.266040413454175\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 862/1000, Training Loss: 0.08740723848927255\n",
      "Epoch 862/1000, Validation Loss: 0.26881581991910936\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 863/1000, Training Loss: 0.0930053447099293\n",
      "Epoch 863/1000, Validation Loss: 0.270627611130476\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 864/1000, Training Loss: 0.09687656611825947\n",
      "Epoch 864/1000, Validation Loss: 0.2662589304149151\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 865/1000, Training Loss: 0.11127612655799762\n",
      "Epoch 865/1000, Validation Loss: 0.2672765776515007\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 866/1000, Training Loss: 0.11084829840589971\n",
      "Epoch 866/1000, Validation Loss: 0.2713977139443159\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 867/1000, Training Loss: 0.08869854930569143\n",
      "Epoch 867/1000, Validation Loss: 0.2673795707523823\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 868/1000, Training Loss: 0.08732542146866237\n",
      "Epoch 868/1000, Validation Loss: 0.2676560807973146\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 869/1000, Training Loss: 0.08734856457843254\n",
      "Epoch 869/1000, Validation Loss: 0.2655777160078287\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 870/1000, Training Loss: 0.08737002157189029\n",
      "Epoch 870/1000, Validation Loss: 0.26710498705506325\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 871/1000, Training Loss: 0.08749870714895866\n",
      "Epoch 871/1000, Validation Loss: 0.26587201505899427\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 872/1000, Training Loss: 0.09216703576784507\n",
      "Epoch 872/1000, Validation Loss: 0.2687566243112087\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 873/1000, Training Loss: 0.09043881282502529\n",
      "Epoch 873/1000, Validation Loss: 0.2647513307631016\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 874/1000, Training Loss: 0.08749670856038802\n",
      "Epoch 874/1000, Validation Loss: 0.2665420599281788\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 875/1000, Training Loss: 0.08789926394820213\n",
      "Epoch 875/1000, Validation Loss: 0.2646918728947639\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 876/1000, Training Loss: 0.08703520254536723\n",
      "Epoch 876/1000, Validation Loss: 0.26428114138543607\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 877/1000, Training Loss: 0.08662591334067139\n",
      "Epoch 877/1000, Validation Loss: 0.26439241990447043\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 878/1000, Training Loss: 0.08666506047616256\n",
      "Epoch 878/1000, Validation Loss: 0.2656536567956209\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 879/1000, Training Loss: 0.08720699661269321\n",
      "Epoch 879/1000, Validation Loss: 0.26578664109110833\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 880/1000, Training Loss: 0.08660755679011345\n",
      "Epoch 880/1000, Validation Loss: 0.2656941652297974\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 881/1000, Training Loss: 0.08636545769724191\n",
      "Epoch 881/1000, Validation Loss: 0.2672559905797243\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 882/1000, Training Loss: 0.08937456634114771\n",
      "Epoch 882/1000, Validation Loss: 0.26576969437301157\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 883/1000, Training Loss: 0.08754499431034121\n",
      "Epoch 883/1000, Validation Loss: 0.2653953328728676\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 884/1000, Training Loss: 0.11730516709241212\n",
      "Epoch 884/1000, Validation Loss: 0.2645368181169033\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 885/1000, Training Loss: 0.1050289320741214\n",
      "Epoch 885/1000, Validation Loss: 0.2636589378118515\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 886/1000, Training Loss: 0.08916597719779056\n",
      "Epoch 886/1000, Validation Loss: 0.2679300747811794\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 887/1000, Training Loss: 0.08787002131415933\n",
      "Epoch 887/1000, Validation Loss: 0.26401297077536584\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 888/1000, Training Loss: 0.08639052671762829\n",
      "Epoch 888/1000, Validation Loss: 0.2644284538924694\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 889/1000, Training Loss: 0.08673158452378023\n",
      "Epoch 889/1000, Validation Loss: 0.26457941234111787\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 890/1000, Training Loss: 0.08624926932594355\n",
      "Epoch 890/1000, Validation Loss: 0.26676269099116323\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 891/1000, Training Loss: 0.09171538821914617\n",
      "Epoch 891/1000, Validation Loss: 0.2734073616564274\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 892/1000, Training Loss: 0.0955702040855791\n",
      "Epoch 892/1000, Validation Loss: 0.27101406157016755\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 893/1000, Training Loss: 0.08877985497555724\n",
      "Epoch 893/1000, Validation Loss: 0.2651345141232014\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 894/1000, Training Loss: 0.08860200480101448\n",
      "Epoch 894/1000, Validation Loss: 0.2652739446610212\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 895/1000, Training Loss: 0.08625948896595076\n",
      "Epoch 895/1000, Validation Loss: 0.2655631624162197\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 896/1000, Training Loss: 0.0881252341410693\n",
      "Epoch 896/1000, Validation Loss: 0.2780304323881865\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 897/1000, Training Loss: 0.08862502793507541\n",
      "Epoch 897/1000, Validation Loss: 0.26744188740849495\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 898/1000, Training Loss: 0.08637089067080221\n",
      "Epoch 898/1000, Validation Loss: 0.26669174432754517\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 899/1000, Training Loss: 0.09181600699529928\n",
      "Epoch 899/1000, Validation Loss: 0.2656191188842058\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 900/1000, Training Loss: 0.08980920675493703\n",
      "Epoch 900/1000, Validation Loss: 0.27001495882868765\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 901/1000, Training Loss: 0.08634323345533773\n",
      "Epoch 901/1000, Validation Loss: 0.2660123843699694\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 902/1000, Training Loss: 0.08591758535750142\n",
      "Epoch 902/1000, Validation Loss: 0.26777893751859666\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 903/1000, Training Loss: 0.08633705969973607\n",
      "Epoch 903/1000, Validation Loss: 0.2672663524746895\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 904/1000, Training Loss: 0.08671786340282243\n",
      "Epoch 904/1000, Validation Loss: 0.26491354033350945\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 905/1000, Training Loss: 0.08572897756947022\n",
      "Epoch 905/1000, Validation Loss: 0.26773108132183554\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 906/1000, Training Loss: 0.08513014850019857\n",
      "Epoch 906/1000, Validation Loss: 0.2659638036042452\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 907/1000, Training Loss: 0.08586125528988002\n",
      "Epoch 907/1000, Validation Loss: 0.26528818123042586\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 908/1000, Training Loss: 0.09210593005021413\n",
      "Epoch 908/1000, Validation Loss: 0.26488064378499987\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 909/1000, Training Loss: 0.09191222140824866\n",
      "Epoch 909/1000, Validation Loss: 0.26376213766634465\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 910/1000, Training Loss: 0.08536650632317122\n",
      "Epoch 910/1000, Validation Loss: 0.2668250102549791\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 911/1000, Training Loss: 0.08614448070818302\n",
      "Epoch 911/1000, Validation Loss: 0.2663755059242249\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 912/1000, Training Loss: 0.08514601647324276\n",
      "Epoch 912/1000, Validation Loss: 0.26492111161351206\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 913/1000, Training Loss: 0.08624978981224915\n",
      "Epoch 913/1000, Validation Loss: 0.27867968156933787\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 914/1000, Training Loss: 0.08567782732833461\n",
      "Epoch 914/1000, Validation Loss: 0.2741837199777365\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 915/1000, Training Loss: 0.08564143054582911\n",
      "Epoch 915/1000, Validation Loss: 0.266132752597332\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 916/1000, Training Loss: 0.08530321892570047\n",
      "Epoch 916/1000, Validation Loss: 0.2657323606312275\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 917/1000, Training Loss: 0.0879186051441174\n",
      "Epoch 917/1000, Validation Loss: 0.26815385520458224\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 918/1000, Training Loss: 0.09118301067136082\n",
      "Epoch 918/1000, Validation Loss: 0.2665581826120615\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 919/1000, Training Loss: 0.17928829051408113\n",
      "Epoch 919/1000, Validation Loss: 0.2980028733611107\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 920/1000, Training Loss: 0.16878323870546677\n",
      "Epoch 920/1000, Validation Loss: 0.27393640801310537\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 921/1000, Training Loss: 0.09383897118124307\n",
      "Epoch 921/1000, Validation Loss: 0.2643426928669214\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 922/1000, Training Loss: 0.08930295367506058\n",
      "Epoch 922/1000, Validation Loss: 0.2656235136091709\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 923/1000, Training Loss: 0.09417443685964041\n",
      "Epoch 923/1000, Validation Loss: 0.2668262518942356\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 924/1000, Training Loss: 0.08829752122070944\n",
      "Epoch 924/1000, Validation Loss: 0.2672095850110054\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 925/1000, Training Loss: 0.0960957104449763\n",
      "Epoch 925/1000, Validation Loss: 0.26682605035603046\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 926/1000, Training Loss: 0.09385284416231454\n",
      "Epoch 926/1000, Validation Loss: 0.276524705439806\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 927/1000, Training Loss: 0.08782334954423063\n",
      "Epoch 927/1000, Validation Loss: 0.26486176140606404\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 928/1000, Training Loss: 0.08512613464231425\n",
      "Epoch 928/1000, Validation Loss: 0.2647044289857149\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 929/1000, Training Loss: 0.08506151272312683\n",
      "Epoch 929/1000, Validation Loss: 0.2651455130428076\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 930/1000, Training Loss: 0.08470986893071904\n",
      "Epoch 930/1000, Validation Loss: 0.2656882587820292\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 931/1000, Training Loss: 0.0849655137019855\n",
      "Epoch 931/1000, Validation Loss: 0.2647684071213007\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 932/1000, Training Loss: 0.08888640780659283\n",
      "Epoch 932/1000, Validation Loss: 0.26542179211974143\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 933/1000, Training Loss: 0.08640463285002054\n",
      "Epoch 933/1000, Validation Loss: 0.2648689702153206\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 934/1000, Training Loss: 0.08478239022436658\n",
      "Epoch 934/1000, Validation Loss: 0.26475344896316527\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 935/1000, Training Loss: 0.08498676315488696\n",
      "Epoch 935/1000, Validation Loss: 0.2676643256098032\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 936/1000, Training Loss: 0.08545220488061507\n",
      "Epoch 936/1000, Validation Loss: 0.26744091138243675\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 937/1000, Training Loss: 0.08598278492105108\n",
      "Epoch 937/1000, Validation Loss: 0.265471088886261\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 938/1000, Training Loss: 0.08407863470418699\n",
      "Epoch 938/1000, Validation Loss: 0.26484329588711264\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 939/1000, Training Loss: 0.0846331697330421\n",
      "Epoch 939/1000, Validation Loss: 0.26634687297046183\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 940/1000, Training Loss: 0.08420669543100338\n",
      "Epoch 940/1000, Validation Loss: 0.2673827841877937\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 941/1000, Training Loss: 0.08874502953361063\n",
      "Epoch 941/1000, Validation Loss: 0.26478583700954916\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 942/1000, Training Loss: 0.08489735879044805\n",
      "Epoch 942/1000, Validation Loss: 0.26535896956920624\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 943/1000, Training Loss: 0.08410746479114774\n",
      "Epoch 943/1000, Validation Loss: 0.2684575218707323\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 944/1000, Training Loss: 0.0837439887373501\n",
      "Epoch 944/1000, Validation Loss: 0.2692027918994427\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 945/1000, Training Loss: 0.08421969979855387\n",
      "Epoch 945/1000, Validation Loss: 0.26454995200037956\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 946/1000, Training Loss: 0.08574049784710594\n",
      "Epoch 946/1000, Validation Loss: 0.2708965927362442\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 947/1000, Training Loss: 0.08511726588453623\n",
      "Epoch 947/1000, Validation Loss: 0.26822123154997823\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 948/1000, Training Loss: 0.08560828893792395\n",
      "Epoch 948/1000, Validation Loss: 0.2655366908758879\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 949/1000, Training Loss: 0.08571183914090415\n",
      "Epoch 949/1000, Validation Loss: 0.26524338871240616\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 950/1000, Training Loss: 0.08401502117311455\n",
      "Epoch 950/1000, Validation Loss: 0.2651214063167572\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 951/1000, Training Loss: 0.08425195301499437\n",
      "Epoch 951/1000, Validation Loss: 0.26524896249175073\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 952/1000, Training Loss: 0.08427447715669534\n",
      "Epoch 952/1000, Validation Loss: 0.2658761031925678\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 953/1000, Training Loss: 0.08519767438445021\n",
      "Epoch 953/1000, Validation Loss: 0.26509461775422094\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 954/1000, Training Loss: 0.08478566047142522\n",
      "Epoch 954/1000, Validation Loss: 0.2649174816906452\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 955/1000, Training Loss: 0.08412599501510461\n",
      "Epoch 955/1000, Validation Loss: 0.26543567702174187\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 956/1000, Training Loss: 0.08686922322593484\n",
      "Epoch 956/1000, Validation Loss: 0.2677660919725895\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 957/1000, Training Loss: 0.08907902918244694\n",
      "Epoch 957/1000, Validation Loss: 0.26520110927522184\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 958/1000, Training Loss: 0.0857981676235795\n",
      "Epoch 958/1000, Validation Loss: 0.26493562906980517\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 959/1000, Training Loss: 0.08556720439125538\n",
      "Epoch 959/1000, Validation Loss: 0.26650064401328566\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 960/1000, Training Loss: 0.08409539193792394\n",
      "Epoch 960/1000, Validation Loss: 0.26602886728942393\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 961/1000, Training Loss: 0.08437228955187279\n",
      "Epoch 961/1000, Validation Loss: 0.26776269301772115\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 962/1000, Training Loss: 0.08610519747091137\n",
      "Epoch 962/1000, Validation Loss: 0.2647753652185202\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 963/1000, Training Loss: 0.08380338173432705\n",
      "Epoch 963/1000, Validation Loss: 0.26572513543069365\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 964/1000, Training Loss: 0.08481961835687067\n",
      "Epoch 964/1000, Validation Loss: 0.27221031710505483\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 965/1000, Training Loss: 0.08550089188673726\n",
      "Epoch 965/1000, Validation Loss: 0.26671233884990214\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 966/1000, Training Loss: 0.08442123369405083\n",
      "Epoch 966/1000, Validation Loss: 0.26606797277927396\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 967/1000, Training Loss: 0.08427364134138984\n",
      "Epoch 967/1000, Validation Loss: 0.2657510232180357\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 968/1000, Training Loss: 0.09067937297125657\n",
      "Epoch 968/1000, Validation Loss: 0.26679519526660445\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 969/1000, Training Loss: 0.089279511860428\n",
      "Epoch 969/1000, Validation Loss: 0.26806070022284983\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 970/1000, Training Loss: 0.08398477643255747\n",
      "Epoch 970/1000, Validation Loss: 0.2661122437566519\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 971/1000, Training Loss: 0.09352961525905366\n",
      "Epoch 971/1000, Validation Loss: 0.267451699078083\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 972/1000, Training Loss: 0.097143608565424\n",
      "Epoch 972/1000, Validation Loss: 0.2656190812587738\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 973/1000, Training Loss: 0.08623002330754317\n",
      "Epoch 973/1000, Validation Loss: 0.26687506176531317\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 974/1000, Training Loss: 0.08512875614870413\n",
      "Epoch 974/1000, Validation Loss: 0.2654622543603182\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 975/1000, Training Loss: 0.08416112025799619\n",
      "Epoch 975/1000, Validation Loss: 0.26591628827154634\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 976/1000, Training Loss: 0.08472435389237087\n",
      "Epoch 976/1000, Validation Loss: 0.26619271039962766\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 977/1000, Training Loss: 0.08625606685253683\n",
      "Epoch 977/1000, Validation Loss: 0.26527745760977267\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 978/1000, Training Loss: 0.08420513280639973\n",
      "Epoch 978/1000, Validation Loss: 0.26544988974928857\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 979/1000, Training Loss: 0.08500135653451377\n",
      "Epoch 979/1000, Validation Loss: 0.26741928383708\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 980/1000, Training Loss: 0.08434445476550358\n",
      "Epoch 980/1000, Validation Loss: 0.2661728385835886\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 981/1000, Training Loss: 0.0844451018481278\n",
      "Epoch 981/1000, Validation Loss: 0.26762564182281495\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 982/1000, Training Loss: 0.08499355101813133\n",
      "Epoch 982/1000, Validation Loss: 0.26624177657067777\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 983/1000, Training Loss: 0.08532177521755882\n",
      "Epoch 983/1000, Validation Loss: 0.26920659057796004\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 984/1000, Training Loss: 0.09716835643584822\n",
      "Epoch 984/1000, Validation Loss: 0.275057764351368\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 985/1000, Training Loss: 0.12187998007763834\n",
      "Epoch 985/1000, Validation Loss: 0.26962567046284674\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 986/1000, Training Loss: 0.085692460447842\n",
      "Epoch 986/1000, Validation Loss: 0.26964045166969297\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 987/1000, Training Loss: 0.08846972079253664\n",
      "Epoch 987/1000, Validation Loss: 0.27042448669672015\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 988/1000, Training Loss: 0.10541070398746752\n",
      "Epoch 988/1000, Validation Loss: 0.27355364970862867\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 989/1000, Training Loss: 0.11882583183750135\n",
      "Epoch 989/1000, Validation Loss: 0.2651799663901329\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 990/1000, Training Loss: 0.08845401570565004\n",
      "Epoch 990/1000, Validation Loss: 0.26409756690263747\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 991/1000, Training Loss: 0.08471661730322476\n",
      "Epoch 991/1000, Validation Loss: 0.2638797234743834\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 992/1000, Training Loss: 0.08414981029379894\n",
      "Epoch 992/1000, Validation Loss: 0.26375666335225106\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 993/1000, Training Loss: 0.08363247971297538\n",
      "Epoch 993/1000, Validation Loss: 0.26396539583802225\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 994/1000, Training Loss: 0.08358229622293216\n",
      "Epoch 994/1000, Validation Loss: 0.2638087529689074\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 995/1000, Training Loss: 0.08307896470468418\n",
      "Epoch 995/1000, Validation Loss: 0.2647321131080389\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 996/1000, Training Loss: 0.08563767702263944\n",
      "Epoch 996/1000, Validation Loss: 0.2645849514752626\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 997/1000, Training Loss: 0.0848733338717983\n",
      "Epoch 997/1000, Validation Loss: 0.26367487721145155\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 998/1000, Training Loss: 0.08234102432342137\n",
      "Epoch 998/1000, Validation Loss: 0.26655536964535714\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 999/1000, Training Loss: 0.08249100809004016\n",
      "Epoch 999/1000, Validation Loss: 0.26446311362087727\n",
      "----------------------------------------------------------------------------------\n",
      "Epoch 1000/1000, Training Loss: 0.08271092313132648\n",
      "Epoch 1000/1000, Validation Loss: 0.2643775768578053\n",
      "----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Net(D_in=x_train.shape[1]).to(device)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define batch size and create data loaders\n",
    "batch_size = 64\n",
    "train_dataset = CustomDataset(x_train.values, y_train.values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(x_val.values, y_val.values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    i=0\n",
    "    for inputs, labels in train_loader:\n",
    "        i+=1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "     \n",
    "        loss = criterion(outputs.squeeze(), labels.squeeze())  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print training loss for this epoch\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Print validation loss for this epoch\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "    print('----------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.11438253841229848\n",
      "Test Accuracy: 96.02%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_dataset = CustomDataset(x_test.values, y_test.values)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted_classes = (outputs >= 0.5).int()  # Convert probabilities to binary predictions\n",
    "        correct_predictions += (predicted_classes == labels).sum().item()\n",
    "        total_samples += len(labels)\n",
    "\n",
    "# Print test loss and accuracy\n",
    "print(f\"Test Loss: {test_loss / len(test_loader)}\")\n",
    "print(f\"Test Accuracy: {correct_predictions / total_samples * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchTabular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
